"""
**********************************************************************

  A RapydScript to JavaScript compiler.
  https://github.com/atsepkov/RapydScript2

  -------------------------------- (C) ---------------------------------

                       Author: Alexander Tsepkov
                         <atsepkov@pyjeon.com>
                         http://www.pyjeon.com

  Distributed under Apache 2.0 license:
    Copyright 2013 (c) Alexander Tsepkov <atsepkov@pyjeon.com>

  RapydScript source code is originally based on UglifyJS2 (covered
  by BSD license). UglifyJS2 was written by Mihai Bazon
  <mihai.bazon@gmail.com>, who is its respective copyright holder.

    Redistribution and use in source and binary forms, with or without
    modification, are permitted provided that the following conditions
    are met:

        * Redistributions of source code must retain the above
          copyright notice, this list of conditions and the following
          disclaimer.

        * Redistributions in binary form must reproduce the above
          copyright notice, this list of conditions and the following
          disclaimer in the documentation and/or other materials
          provided with the distribution.

    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDER “AS IS” AND ANY
    EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
    PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE
    LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
    PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
    PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
    THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
    TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF
    THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
    SUCH DAMAGE.

**********************************************************************
"""
"use strict"

KEYWORDS = "as break case class const continue debugger default def del do elif else except finally for from if import require in instanceof is module new nonlocal pass raise return switch til to try typeof var void while with or and not"

KEYWORDS_ATOM = "False None True"

RESERVED_WORDS = "abstract boolean byte char double enum export extends final float goto implements int interface long native package private protected public short static super synchronized this throws transient volatile" + " " + KEYWORDS_ATOM + " " + KEYWORDS

KEYWORDS_BEFORE_EXPRESSION = "return new del raise elif else if"

KEYWORDS = makePredicate(KEYWORDS)
RESERVED_WORDS = makePredicate(RESERVED_WORDS)
KEYWORDS_BEFORE_EXPRESSION = makePredicate(KEYWORDS_BEFORE_EXPRESSION)
KEYWORDS_ATOM = makePredicate(KEYWORDS_ATOM)

NATIVE_CLASSES = {
    'Image': {},
    'RegExp': {},
    'Error': {},
    'Object': {
        static: [ "getOwnPropertyNames", "keys", "create" ]
    },
    'String': {
        static: [ "fromCharCode" ]
    },
    'Array': {
        static: [ "isArray", "from", "of" ]
    },
    'Number': {
        static: [ "isFinite", "isNaN" ]
    },
    'Function': {},
    'Date': {
        static: [ "UTC", "now", "parse" ]
    },
    'Boolean': {},
    'ArrayBuffer': {},
    'DataView': {},
    'Float32Array': {},
    'Float64Array': {},
    'Int16Array': {},
    'Int32Array': {},
    'Int8Array': {},
    'Uint16Array': {},
    'Uint32Array': {},
    'Uint8Array': {},
    'Uint8ClampedArray': {}
}

OPERATOR_CHARS = makePredicate(characters("+-*&%=<>!?|~^@"))

RE_HEX_NUMBER = /^0x[0-9a-f]+$/i
RE_OCT_NUMBER = /^0[0-7]+$/
RE_DEC_NUMBER = /^\d*\.?\d*(?:e[+-]?\d*(?:\d\.?|\.?\d)\d*)?$/i

OPERATORS = makePredicate([ "in", "instanceof", "typeof", "new", "void", "del", "++", "--", "+", "-", "not", "~", "&", "|", "^", "*", "/", "%", ">>", "<<", ">>>", "<", ">", "<=", ">=", "==", "is", "!=", "!==", "?", "=", "+=", "-=", "/=", "*=", "%=", ">>=", "<<=", ">>>=", "|=", "^=", "&=", "and", "or", "til", "to", "@" ])

OP_MAP = {
    'or': "||",
    'and': "&&",
    'not': "!",
    'del': "delete",
    'None': "null",
    'is': "==="
}

WHITESPACE_CHARS = makePredicate(characters(" \u00a0\n\r\t\f\u000b\u200b\u180e\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007\u2008\u2009\u200a\u202f\u205f\u3000"));

PUNC_BEFORE_EXPRESSION = makePredicate(characters("[{(,.;:"))

PUNC_CHARS = makePredicate(characters("[]{}(),;:"))

REGEXP_MODIFIERS = makePredicate(characters("gmsiy"))

# -----[ Tokenizer ]-----
# regexps adapted from http://xregexp.com/plugins/#unicode
UNICODE = {
    letter: RegExp("[\\u0041-\\u005A\\u0061-\\u007A\\u00AA\\u00B5\\u00BA\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02C1\\u02C6-\\u02D1\\u02E0-\\u02E4\\u02EC\\u02EE\\u0370-\\u0374\\u0376\\u0377\\u037A-\\u037D\\u0386\\u0388-\\u038A\\u038C\\u038E-\\u03A1\\u03A3-\\u03F5\\u03F7-\\u0481\\u048A-\\u0523\\u0531-\\u0556\\u0559\\u0561-\\u0587\\u05D0-\\u05EA\\u05F0-\\u05F2\\u0621-\\u064A\\u066E\\u066F\\u0671-\\u06D3\\u06D5\\u06E5\\u06E6\\u06EE\\u06EF\\u06FA-\\u06FC\\u06FF\\u0710\\u0712-\\u072F\\u074D-\\u07A5\\u07B1\\u07CA-\\u07EA\\u07F4\\u07F5\\u07FA\\u0904-\\u0939\\u093D\\u0950\\u0958-\\u0961\\u0971\\u0972\\u097B-\\u097F\\u0985-\\u098C\\u098F\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BD\\u09CE\\u09DC\\u09DD\\u09DF-\\u09E1\\u09F0\\u09F1\\u0A05-\\u0A0A\\u0A0F\\u0A10\\u0A13-\\u0A28\\u0A2A-\\u0A30\\u0A32\\u0A33\\u0A35\\u0A36\\u0A38\\u0A39\\u0A59-\\u0A5C\\u0A5E\\u0A72-\\u0A74\\u0A85-\\u0A8D\\u0A8F-\\u0A91\\u0A93-\\u0AA8\\u0AAA-\\u0AB0\\u0AB2\\u0AB3\\u0AB5-\\u0AB9\\u0ABD\\u0AD0\\u0AE0\\u0AE1\\u0B05-\\u0B0C\\u0B0F\\u0B10\\u0B13-\\u0B28\\u0B2A-\\u0B30\\u0B32\\u0B33\\u0B35-\\u0B39\\u0B3D\\u0B5C\\u0B5D\\u0B5F-\\u0B61\\u0B71\\u0B83\\u0B85-\\u0B8A\\u0B8E-\\u0B90\\u0B92-\\u0B95\\u0B99\\u0B9A\\u0B9C\\u0B9E\\u0B9F\\u0BA3\\u0BA4\\u0BA8-\\u0BAA\\u0BAE-\\u0BB9\\u0BD0\\u0C05-\\u0C0C\\u0C0E-\\u0C10\\u0C12-\\u0C28\\u0C2A-\\u0C33\\u0C35-\\u0C39\\u0C3D\\u0C58\\u0C59\\u0C60\\u0C61\\u0C85-\\u0C8C\\u0C8E-\\u0C90\\u0C92-\\u0CA8\\u0CAA-\\u0CB3\\u0CB5-\\u0CB9\\u0CBD\\u0CDE\\u0CE0\\u0CE1\\u0D05-\\u0D0C\\u0D0E-\\u0D10\\u0D12-\\u0D28\\u0D2A-\\u0D39\\u0D3D\\u0D60\\u0D61\\u0D7A-\\u0D7F\\u0D85-\\u0D96\\u0D9A-\\u0DB1\\u0DB3-\\u0DBB\\u0DBD\\u0DC0-\\u0DC6\\u0E01-\\u0E30\\u0E32\\u0E33\\u0E40-\\u0E46\\u0E81\\u0E82\\u0E84\\u0E87\\u0E88\\u0E8A\\u0E8D\\u0E94-\\u0E97\\u0E99-\\u0E9F\\u0EA1-\\u0EA3\\u0EA5\\u0EA7\\u0EAA\\u0EAB\\u0EAD-\\u0EB0\\u0EB2\\u0EB3\\u0EBD\\u0EC0-\\u0EC4\\u0EC6\\u0EDC\\u0EDD\\u0F00\\u0F40-\\u0F47\\u0F49-\\u0F6C\\u0F88-\\u0F8B\\u1000-\\u102A\\u103F\\u1050-\\u1055\\u105A-\\u105D\\u1061\\u1065\\u1066\\u106E-\\u1070\\u1075-\\u1081\\u108E\\u10A0-\\u10C5\\u10D0-\\u10FA\\u10FC\\u1100-\\u1159\\u115F-\\u11A2\\u11A8-\\u11F9\\u1200-\\u1248\\u124A-\\u124D\\u1250-\\u1256\\u1258\\u125A-\\u125D\\u1260-\\u1288\\u128A-\\u128D\\u1290-\\u12B0\\u12B2-\\u12B5\\u12B8-\\u12BE\\u12C0\\u12C2-\\u12C5\\u12C8-\\u12D6\\u12D8-\\u1310\\u1312-\\u1315\\u1318-\\u135A\\u1380-\\u138F\\u13A0-\\u13F4\\u1401-\\u166C\\u166F-\\u1676\\u1681-\\u169A\\u16A0-\\u16EA\\u1700-\\u170C\\u170E-\\u1711\\u1720-\\u1731\\u1740-\\u1751\\u1760-\\u176C\\u176E-\\u1770\\u1780-\\u17B3\\u17D7\\u17DC\\u1820-\\u1877\\u1880-\\u18A8\\u18AA\\u1900-\\u191C\\u1950-\\u196D\\u1970-\\u1974\\u1980-\\u19A9\\u19C1-\\u19C7\\u1A00-\\u1A16\\u1B05-\\u1B33\\u1B45-\\u1B4B\\u1B83-\\u1BA0\\u1BAE\\u1BAF\\u1C00-\\u1C23\\u1C4D-\\u1C4F\\u1C5A-\\u1C7D\\u1D00-\\u1DBF\\u1E00-\\u1F15\\u1F18-\\u1F1D\\u1F20-\\u1F45\\u1F48-\\u1F4D\\u1F50-\\u1F57\\u1F59\\u1F5B\\u1F5D\\u1F5F-\\u1F7D\\u1F80-\\u1FB4\\u1FB6-\\u1FBC\\u1FBE\\u1FC2-\\u1FC4\\u1FC6-\\u1FCC\\u1FD0-\\u1FD3\\u1FD6-\\u1FDB\\u1FE0-\\u1FEC\\u1FF2-\\u1FF4\\u1FF6-\\u1FFC\\u2071\\u207F\\u2090-\\u2094\\u2102\\u2107\\u210A-\\u2113\\u2115\\u2119-\\u211D\\u2124\\u2126\\u2128\\u212A-\\u212D\\u212F-\\u2139\\u213C-\\u213F\\u2145-\\u2149\\u214E\\u2183\\u2184\\u2C00-\\u2C2E\\u2C30-\\u2C5E\\u2C60-\\u2C6F\\u2C71-\\u2C7D\\u2C80-\\u2CE4\\u2D00-\\u2D25\\u2D30-\\u2D65\\u2D6F\\u2D80-\\u2D96\\u2DA0-\\u2DA6\\u2DA8-\\u2DAE\\u2DB0-\\u2DB6\\u2DB8-\\u2DBE\\u2DC0-\\u2DC6\\u2DC8-\\u2DCE\\u2DD0-\\u2DD6\\u2DD8-\\u2DDE\\u2E2F\\u3005\\u3006\\u3031-\\u3035\\u303B\\u303C\\u3041-\\u3096\\u309D-\\u309F\\u30A1-\\u30FA\\u30FC-\\u30FF\\u3105-\\u312D\\u3131-\\u318E\\u31A0-\\u31B7\\u31F0-\\u31FF\\u3400\\u4DB5\\u4E00\\u9FC3\\uA000-\\uA48C\\uA500-\\uA60C\\uA610-\\uA61F\\uA62A\\uA62B\\uA640-\\uA65F\\uA662-\\uA66E\\uA67F-\\uA697\\uA717-\\uA71F\\uA722-\\uA788\\uA78B\\uA78C\\uA7FB-\\uA801\\uA803-\\uA805\\uA807-\\uA80A\\uA80C-\\uA822\\uA840-\\uA873\\uA882-\\uA8B3\\uA90A-\\uA925\\uA930-\\uA946\\uAA00-\\uAA28\\uAA40-\\uAA42\\uAA44-\\uAA4B\\uAC00\\uD7A3\\uF900-\\uFA2D\\uFA30-\\uFA6A\\uFA70-\\uFAD9\\uFB00-\\uFB06\\uFB13-\\uFB17\\uFB1D\\uFB1F-\\uFB28\\uFB2A-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBB1\\uFBD3-\\uFD3D\\uFD50-\\uFD8F\\uFD92-\\uFDC7\\uFDF0-\\uFDFB\\uFE70-\\uFE74\\uFE76-\\uFEFC\\uFF21-\\uFF3A\\uFF41-\\uFF5A\\uFF66-\\uFFBE\\uFFC2-\\uFFC7\\uFFCA-\\uFFCF\\uFFD2-\\uFFD7\\uFFDA-\\uFFDC]"),
    non_spacing_mark: RegExp("[\\u0300-\\u036F\\u0483-\\u0487\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u064B-\\u065E\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0900-\\u0902\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0955\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0CBC\\u0CBF\\u0CC6\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EB9\\u0EBB\\u0EBC\\u0EC8-\\u0ECD\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F90-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135F\\u1712-\\u1714\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1DC0-\\u1DE6\\u1DFD-\\u1DFF\\u20D0-\\u20DC\\u20E1\\u20E5-\\u20F0\\u2CEF-\\u2CF1\\u2DE0-\\u2DFF\\u302A-\\u302F\\u3099\\u309A\\uA66F\\uA67C\\uA67D\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA8C4\\uA8E0-\\uA8F1\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE26]"),
    space_combining_mark: RegExp("[\\u0903\\u093E-\\u0940\\u0949-\\u094C\\u094E\\u0982\\u0983\\u09BE-\\u09C0\\u09C7\\u09C8\\u09CB\\u09CC\\u09D7\\u0A03\\u0A3E-\\u0A40\\u0A83\\u0ABE-\\u0AC0\\u0AC9\\u0ACB\\u0ACC\\u0B02\\u0B03\\u0B3E\\u0B40\\u0B47\\u0B48\\u0B4B\\u0B4C\\u0B57\\u0BBE\\u0BBF\\u0BC1\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCC\\u0BD7\\u0C01-\\u0C03\\u0C41-\\u0C44\\u0C82\\u0C83\\u0CBE\\u0CC0-\\u0CC4\\u0CC7\\u0CC8\\u0CCA\\u0CCB\\u0CD5\\u0CD6\\u0D02\\u0D03\\u0D3E-\\u0D40\\u0D46-\\u0D48\\u0D4A-\\u0D4C\\u0D57\\u0D82\\u0D83\\u0DCF-\\u0DD1\\u0DD8-\\u0DDF\\u0DF2\\u0DF3\\u0F3E\\u0F3F\\u0F7F\\u102B\\u102C\\u1031\\u1038\\u103B\\u103C\\u1056\\u1057\\u1062-\\u1064\\u1067-\\u106D\\u1083\\u1084\\u1087-\\u108C\\u108F\\u109A-\\u109C\\u17B6\\u17BE-\\u17C5\\u17C7\\u17C8\\u1923-\\u1926\\u1929-\\u192B\\u1930\\u1931\\u1933-\\u1938\\u19B0-\\u19C0\\u19C8\\u19C9\\u1A19-\\u1A1B\\u1A55\\u1A57\\u1A61\\u1A63\\u1A64\\u1A6D-\\u1A72\\u1B04\\u1B35\\u1B3B\\u1B3D-\\u1B41\\u1B43\\u1B44\\u1B82\\u1BA1\\u1BA6\\u1BA7\\u1BAA\\u1C24-\\u1C2B\\u1C34\\u1C35\\u1CE1\\u1CF2\\uA823\\uA824\\uA827\\uA880\\uA881\\uA8B4-\\uA8C3\\uA952\\uA953\\uA983\\uA9B4\\uA9B5\\uA9BA\\uA9BB\\uA9BD-\\uA9C0\\uAA2F\\uAA30\\uAA33\\uAA34\\uAA4D\\uAA7B\\uABE3\\uABE4\\uABE6\\uABE7\\uABE9\\uABEA\\uABEC]"),
    connector_punctuation: RegExp("[\\u005F\\u203F\\u2040\\u2054\\uFE33\\uFE34\\uFE4D-\\uFE4F\\uFF3F]")
}

IMPORTED = {}
BASELIB = {}

def is_letter(code):
    return code >= 97 and code <= 122 or code >= 65 and code <= 90 or code >= 170 and UNICODE.letter.test(String.fromCharCode(code))

def is_digit(code):
    return code >= 48 and code <= 57

def is_alphanumeric_char(code):
    return is_digit(code) or is_letter(code)

def is_unicode_combining_mark(ch):
    return UNICODE.non_spacing_mark.test(ch) or UNICODE.space_combining_mark.test(ch)

def is_unicode_connector_punctuation(ch):
    return UNICODE.connector_punctuation.test(ch)

def is_identifier(name):
    return not RESERVED_WORDS(name) and /^[a-z_$][a-z0-9_$]*$/i.test(name)

def is_identifier_start(code):
    return code == 36 or code == 95 or is_letter(code)

def is_identifier_char(ch):
    code = ch.charCodeAt(0)
    return is_identifier_start(code) or is_digit(code) or code == 8204 or code == 8205 or is_unicode_combining_mark(ch) or is_unicode_connector_punctuation(ch)

def parse_js_number(num):
    if RE_HEX_NUMBER.test(num):
        return parseInt(num.substr(2), 16)
    elif RE_OCT_NUMBER.test(num):
        return parseInt(num.substr(1), 8)
    elif RE_DEC_NUMBER.test(num):
        return parseFloat(num)

def JS_Parse_Error(message, line, col, pos):
    this.message = message
    this.line = line
    this.col = col
    this.pos = pos
    this.stack = Error().stack

JS_Parse_Error.prototype.toString = def():
    return this.message + " (line: " + this.line + ", col: " + this.col + ", pos: " + this.pos + ")" + "\n\n" + this.stack

def js_error(message, filename, line, col, pos):
    AST_Node.warn("ERROR: {message} [{file}:{line},{col}]", {
        message: message,
        file: filename,
        line: line,
        col: col
    })
    raise new JS_Parse_Error(message, line, col, pos)

def is_token(token, type, val):
    return token.type == type and (val == None or token.value == val)

def reserved_decorator(s, decorator):
    if not s.decorators:
        return False
        
    index = s.decorators.indexOf(decorator)
    found = index != -1
    if found:
        s.decorators.splice(index, 1)

    return found
    
EX_EOF = {}

def tokenizer($TEXT, filename):
    S = {
        text: $TEXT.replace(/\r\n?|[\n\u2028\u2029]/g, "\n").replace(/\uFEFF/g, ""),
        filename: filename,
        pos: 0,
        tokpos: 0,
        line: 1,
        tokline: 0,
        col: 0,
        tokcol: 0,
        newline_before: False,
        regex_allowed: False,
        comments_before: [],
        whitespace_before: [],
        newblock: False,
        endblock: False,
        indentation_matters: [ True ],
        cached_whitespace: "",
        prev: undefined,
        index_or_slice: [ False ]
    }
    def peek():
        return S.text.charAt(S.pos)

    def prevChar():
        return S.text.charAt(S.tokpos - 1)

    def next(signal_eof, in_string):
        ch = S.text.charAt(S.pos)
        S.pos += 1
        if signal_eof and not ch:
            raise EX_EOF

        if ch == "\n":
            S.newline_before = S.newline_before or not in_string
            S.line += 1
            S.col = 0
        else:
            S.col += 1
        return ch

    def find(what, signal_eof):
        pos = S.text.indexOf(what, S.pos)
        if signal_eof and pos == -1:
            raise EX_EOF
        return pos

    def start_token():
        S.tokline = S.line
        S.tokcol = S.col
        S.tokpos = S.pos

    def token(type, value, is_comment, keep_newline):
        S.regex_allowed = type == "operator" and not UNARY_POSTFIX[value] \
            or type == "keyword" and KEYWORDS_BEFORE_EXPRESSION(value) \
            or type == "punc" and PUNC_BEFORE_EXPRESSION(value)

        if type == "operator" and value == "is" and S.text.substr(S.pos).trimLeft().substr(0, 4).trimRight() == "not":
            next_token()
            value = "!=="

        if type == "operator" and OP_MAP[value]:
            value = OP_MAP[value]

        ret = {
            type: type,
            value: value,
            line: S.tokline,
            col: S.tokcol,
            pos: S.tokpos,
            endpos: S.pos,
            nlb: S.newline_before,
            file: filename
        }
        if not is_comment:
            ret.comments_before = S.comments_before
            S.comments_before = []
            # make note of any newlines in the comments that came before
            for i in range(len(ret.comments_before)):
                ret.nlb = ret.nlb or ret.comments_before[i].nlb

        if not keep_newline:
            S.newline_before = False

        if type == "punc":
            #            if (value == ":" && peek() == "\n") {
            if value == ":" and not S.index_or_slice.slice(-1)[0]
            and (not S.text.substring(S.pos + 1, find("\n")).trim() or not S.text.substring(S.pos + 1, find("#")).trim()):
                S.newblock = True
                S.indentation_matters.push(True)

            if value == "[":
                if S.prev and S.prev.type == "name":
                    S.index_or_slice.push(True)
                else:
                    S.index_or_slice.push(False)
                S.indentation_matters.push(False)
            elif value == "{" or value == "(":
                S.indentation_matters.push(False)
            elif value == "]":
                S.index_or_slice.pop()
                S.indentation_matters.pop()
            elif value == "}" or value == ")":
                S.indentation_matters.pop()
        S.prev = new AST_Token(ret)
        return S.prev

    # this will transform leading whitespace to block tokens unless
    # part of array/hash, and skip non-leading whitespace
    def parse_whitespace():
        leading_whitespace = ""
        whitespace_exists = False
        while WHITESPACE_CHARS(peek()):
            whitespace_exists = True
            ch = next()
            if ch == "\n":
                leading_whitespace = ""
            else:
                leading_whitespace += ch
        if peek() != "#":
            if not whitespace_exists:
                leading_whitespace = S.cached_whitespace
            else:
                S.cached_whitespace = leading_whitespace
            if S.newline_before or S.endblock:
                return test_indent_token(leading_whitespace)

    def test_indent_token(leading_whitespace):
        most_recent = S.whitespace_before[S.whitespace_before.length - 1] or ""
        S.endblock = False
        if S.indentation_matters.slice(-1)[0] and leading_whitespace != most_recent:
            if S.newblock and leading_whitespace and leading_whitespace.indexOf(most_recent) == 0:
                # positive indent, new block
                S.newblock = False
                S.whitespace_before.push(leading_whitespace)
                return 1
            elif most_recent and most_recent.indexOf(leading_whitespace) == 0:
                # negative indent, block is ending
                S.endblock = True
                S.whitespace_before.pop()
                return -1
            else:
                # indent mismatch, inconsistent indentation
                parse_error("Inconsistent indentation")
        else:
            return 0

    def read_while(pred):
        ret = ""
        i = 0
        while (ch = peek()) and pred(ch, i):
            i += 1
            ret += next()
        return ret

    def parse_error(err):
        js_error(err, filename, S.tokline, S.tokcol, S.tokpos)

    def read_num(prefix):
        has_e = False
        after_e = False
        has_x = False
        has_dot = prefix == "."
        num = read_while(def(ch, i):
            code = ch.charCodeAt(0)
            tmp_ = code
            if tmp_ == 120 or tmp_ == 88:
                # xX
                return (has_x ? False : has_x = True)
            elif tmp_ == 101 or tmp_ == 69:
                # eE
                return (has_x ? True : (has_e ? False : has_e = after_e = True))
            elif tmp_ == 45:
                # -
                return after_e or i == 0 and not prefix
            elif tmp_ == 43:
                # +
                return after_e
            elif tmp_ == 46:
                # .
                after_e = False
                return (not has_dot and not has_x and not has_e ? has_dot = True : False)
            return is_alphanumeric_char(code)
        )
        if prefix:
            num = prefix + num

        valid = parse_js_number(num)
        if not isNaN(valid):
            return token("num", valid)
        else:
            parse_error("Invalid syntax: " + num)


    def read_escaped_char(in_string, digester):
        digester = digester or def(in_str):
            return next(True, in_str)

        ch = digester(in_string)
        tmp_ = ch.charCodeAt(0)
        if tmp_ == 110:
            return "\n"
        elif tmp_ == 114:
            return "\r"
        elif tmp_ == 116:
            return "	"
        elif tmp_ == 98:
            return "\b"
        elif tmp_ == 118:
            return "\u000b" # \v
        elif tmp_ == 102:
            return "\f"
        elif tmp_ == 48:
            return "\0"
        elif tmp_ == 120:
            return String.fromCharCode(hex_bytes(2, digester))  # \x
        elif tmp_ == 117:
            return String.fromCharCode(hex_bytes(4, digester))  # \u
        elif tmp_ == 10:
            return ""   # newline
        else:
            return ch

    def hex_bytes(n, digester):
        num = 0
        for i in range(n):
            digit = parseInt(digester(), 16)
            if isNaN(digit):
                parse_error("Invalid hex-character pattern in string")
            num = num << 4 | digit
        return num

    read_string = with_eof_error("Unterminated string constant", def():
        quote = next()
        ret = ""
        if peek() == quote:
            next(True)
            if peek() == quote:
                # multiline string
                next(True)
                i = find(quote + quote + quote, True)
                if i != -1:
                    tmp = S.text.substring(S.pos, i)
                    S.pos = i + 3
                    while tmp.length:
                        if tmp[0] == "\\":
                            tmp = tmp.substr(1)
                            ret += read_escaped_char(True, def():
                                nonlocal tmp
                                ch = tmp[0]
                                tmp = tmp.substr(1)
                                return ch
                            )
                        else:
                            ret += tmp[0]
                            tmp = tmp.substr(1)
                    return token("string", ret)
            else:
                return token("string", "")

        while True:
            ch = next(True)
            if ch == "\n":
                parse_error("End of line while scanning string literal.")

            if ch == "\\":
                # read OctalEscapeSequence (XXX: deprecated if "strict mode")
                # https://github.com/mishoo/RapydScript/issues/178
                octal_len = 0
                first = None
                ch = read_while(def(ch):
                    nonlocal first
                    if ch >= "0" and ch <= "7":
                        if not first:
                            first = ch
                            return octal_len += 1
                        elif first <= "3" and octal_len <= 2:
                            return octal_len += 1
                        elif first >= "4" and octal_len <= 1:
                            return octal_len += 1
                    return False
                )
                if octal_len > 0:
                    ch = String.fromCharCode(parseInt(ch, 8))
                elif peek() == "\n":
                    # skip newlines if escaped by backslash
                    next(True)
                    continue
                else:
                    ch = read_escaped_char(True)
            elif ch == quote:
                break
            ret += ch
        return token("string", ret)
    )

    def read_line_comment():
        next()
        i = find("\n")

        if i == -1:
            ret = S.text.substr(S.pos)
            S.pos = S.text.length
        else:
            ret = S.text.substring(S.pos, i)
            S.pos = i

        return token("comment1", ret, True)

    read_multiline_comment = with_eof_error("Unterminated multiline comment", def():
        next()
        i = find("*/", True)
        text = S.text.substring(S.pos, i)
        a = text.split("\n")
        n = a.length
        # update stream position
        S.pos = i + 2
        S.line += n - 1
        if n > 1:
            S.col = a[n - 1].length
        else:
            S.col += a[n - 1].length
        S.col += 2
        S.newline_before = S.newline_before or text.indexOf("\n") >= 0
        return token("comment2", text, True)
    )
    def read_name():
        backslash = False
        name = ""
        escaped = False

        while (ch = peek()) != None:
            if not backslash:
                if ch == "\\":
                    if S.text.charAt(S.pos + 1) == "\n":
                        S.pos += 2
                        continue
                    else:
                        escaped = backslash = True, next()
                elif is_identifier_char(ch):
                    name += next()
                else:
                    break
            else:
                if ch != "u":
                    parse_error("Expecting UnicodeEscapeSequence -- uXXXX")
                ch = read_escaped_char()
                if not is_identifier_char(ch):
                    parse_error("Unicode char: " + ch.charCodeAt(0) + " is not valid in identifier")
                name += ch
                backslash = False

        if KEYWORDS(name) and escaped:
            hex = name.charCodeAt(0).toString(16).toUpperCase()
            name = "\\u" + "0000".substr(hex.length) + hex + name.slice(1)
        return name

    read_regexp = with_eof_error("Unterminated regular expression", def(regexp):
        prev_backslash = False

        in_class = False
        while ch = next(True):
            if prev_backslash:
                regexp += "\\" + ch
                prev_backslash = False
            elif ch == "[":
                in_class = True
                regexp += ch
            elif ch == "]" and in_class:
                in_class = False
                regexp += ch
            elif ch == "/" and not in_class:
                break
            elif ch == "\\":
                prev_backslash = True
            else:
                regexp += ch

        mods = read_name()
        return token("regexp", RegExp(regexp, mods))
    )
    def read_operator(prefix):
        def grow(op):
            if not peek():
                return op

            bigger = op + peek()
            if OPERATORS(bigger):
                next()
                return grow(bigger)
            else:
                return op
        return token("operator", grow(prefix or next()))

    def handle_slash():
        next()
        regex_allowed = S.regex_allowed
        tmp_ = peek()
        if tmp_ == "/":
            S.comments_before.push(read_line_comment())
            S.regex_allowed = regex_allowed
            return next_token()
        elif tmp_ == "*":
            S.comments_before.push(read_multiline_comment())
            S.regex_allowed = regex_allowed
            return next_token()

        return (S.regex_allowed ? read_regexp("") : read_operator("/"))

    def handle_dot():
        next()
        return (is_digit(peek().charCodeAt(0)) ? read_num(".") : token("punc", "."))

    def read_word():
        word = read_name()
        return (KEYWORDS_ATOM(word) ? token("atom", word) : (not KEYWORDS(word) ? token("name", word) : (OPERATORS(word) and prevChar() != "." ? token("operator", word) : token("keyword", word))))

    def with_eof_error(eof_error, cont):
        return def(x):
            try:
                return cont(x)
            except as ex:
                if ex is EX_EOF:
                    parse_error(eof_error)
                else:
                    raise

    def next_token(force_regexp):
        if force_regexp != None:
            return read_regexp(force_regexp)

        indent = parse_whitespace()
        #        if (indent == 1)
        #            return token("punc", "{");
        if indent == -1:
            return token("punc", "}", False, True)

        start_token()
        ch = peek()
        if not ch:
            return token("eof")

        code = ch.charCodeAt(0)
        tmp_ = code
        if tmp_ == 34 or tmp_ == 39:
            return read_string()
        elif tmp_ == 35:
            regex_allowed = S.regex_allowed
            S.comments_before.push(read_line_comment())
            S.regex_allowed = regex_allowed
            return next_token()
        elif tmp_ == 46:
            return handle_dot()
        elif tmp_ == 47:
            return handle_slash()

        if is_digit(code):
            return read_num()

        if PUNC_CHARS(ch):
            return token("punc", next())

        if OPERATOR_CHARS(ch):
            return read_operator()

        if code == 92 and S.text.charAt(S.pos + 1) == "\n":
            # backslash will consume the newline character that follows
            next()
            # backslash
            next()
            # newline
            S.newline_before = False
            return next_token()

        if code == 92 or is_identifier_start(code):
            return read_word()

        parse_error("Unexpected character «" + ch + "»")

    next_token.context = def(nc):
        nonlocal S
        if nc:
            S = nc
        return S

    return next_token


# -----[ Parser (constants) ]-----
UNARY_PREFIX = makePredicate([
    "typeof",
    "void",
    "delete",
    "--",
    "++",
    "!",
    "~",
    "-",
    "+",
    "@"
])

UNARY_POSTFIX = makePredicate([ "--", "++" ])

ASSIGNMENT = makePredicate([ "=", "+=", "-=", "/=", "*=", "%=", ">>=", "<<=", ">>>=", "|=", "^=", "&=" ])

PRECEDENCE = def(a, ret):
    for i in range(a.length):
        b = a[i]
        for j in range(b.length):
            ret[b[j]] = i+1
    return ret
.call(this, [
    [ "||" ],
    [ "&&" ],
    [ "|" ],
    [ "^" ],
    [ "&" ],
    [ "==", "===", "!=", "!==" ],
    [ "<", ">", "<=", ">=", "in", "instanceof" ],
    [ ">>", "<<", ">>>" ], [ "+", "-" ],
    [ "*", "/", "%" ]
], {})

STATEMENTS_WITH_LABELS = array_to_hash([ "for", "do", "while", "switch" ])

ATOMIC_START_TOKEN = array_to_hash([ "atom", "num", "string", "regexp", "name" ])

# -----[ Parser ]-----
def parse($TEXT, options):

    options = defaults(options, {
        strict: False,
        filename: None,
        auto_bind: False,
        toplevel: None
    })

    S = {
        input: (typeof $TEXT == "string" ? tokenizer($TEXT, options.filename) : $TEXT),
        token: None,
        prev: None,
        peeked: None,
        in_function: 0,
        in_directives: True,
        in_loop: 0,
        in_class: [ False ],
        classes: [ {} ],
        labels: [],
        decorators: [],
        module_tree: {},
        # tree describing the structure of modules and classes within them (module: {}, class: undefined)
        module_stack: []
    }

    S.token = next()
    def is_(type, value):
        return is_token(S.token, type, value)

    def peek():
        return S.peeked or (S.peeked = S.input())

    def next():
        S.prev = S.token
        if S.peeked:
            S.token = S.peeked
            S.peeked = None
        else:
            S.token = S.input()

        S.in_directives = S.in_directives and (S.token.type == "string" or is_("punc", ";"))
        return S.token

    def prev():
        return S.prev

    def croak(msg, line, col, pos):
        ctx = S.input.context()
        js_error(msg, ctx.filename, (line != None ? line : ctx.tokline),
                 (col != None ? col : ctx.tokcol), (pos != None ? pos : ctx.tokpos))

    def token_error(token, msg):
        croak(msg, token.line, token.col)

    def unexpected(token):
        if token == None:
            token = S.token
        token_error(token, "Unexpected token: " + token.type + " «" + token.value + "»")

    def expect_token(type, val):
        if is_(type, val):
            return next()
        token_error(S.token, "Unexpected token " + S.token.type + " «" + S.token.value + "»" +
                    ", expected " + type + " «" + val + "»")

    def expect(punc):
        return expect_token("punc", punc)

    def can_insert_semicolon():
        return not options.strict and (S.token.nlb or is_("eof") or is_("punc", "}"))

    def semicolon():
        if is_("punc", ";"):
            next()
            S.token.nlb = True

    def parenthesised():
        expect("(")
        exp = expression(True)
        expect(")")
        return exp

    def embed_tokens(parser):
        return def():
            start = S.token
            expr = parser()
            end = prev()
            expr.start = start
            expr.end = end
            return expr

    def scan_for_local_vars(body, is_module):
        vars = []
        if isinstance(body, Array):
            for stmt in dir(body):
                if isinstance(body[stmt], AST_Scope):
                    if is_module and body[stmt].name:
                        vars.push(body[stmt].name)
                    continue

                [ "body", "alternative" ].forEach(def(option):
                    nonlocal vars
                    opt = body[stmt][option]
                    if opt:
                        vars = vars.concat(scan_for_local_vars(opt, is_module))

                    if opt and opt.operator == "=" and not (isinstance(opt.right, AST_Scope)):
                        vars = vars.concat(scan_for_local_vars(opt.right, is_module))
                )

                # pick up iterators from loops
                if not is_module:
                    if isinstance(body[stmt], AST_ForIn):
                        if isinstance(body[stmt].init, AST_Array):
                            vars.push("_$rapyd$_Unpack")
                            body[stmt].init.elements.forEach(def(elem):
                                if vars.indexOf(elem.name) == -1:
                                    vars.push(elem.name)
                            )
                        elif vars.indexOf(body[stmt].init.name) == -1:
                            vars.push(body[stmt].init.name)
                    elif isinstance(body[stmt], AST_DWLoop):
                        vars = vars.concat(scan_for_local_vars(body[stmt], is_module))

        elif body and body.body:
            vars = vars.concat(scan_for_local_vars(body.body, is_module))
            if body.alternative:
                vars = vars.concat(scan_for_local_vars(body.alternative, is_module))

        elif isinstance(body, AST_Assign):
            if isinstance(body.left, AST_Array):
                vars.push("_$rapyd$_Unpack")
                body.left.elements.forEach(def(elem):
                    if not (isinstance(elem, AST_PropAccess)) and vars.indexOf(elem.name) == -1:
                        vars.push(elem.name)
                )
            elif body.left.name and vars.indexOf(body.left.name) == -1:
                vars.push(body.left.name)

        return vars

    def scan_for_nonlocal_defs(body):
        vars = []
        if isinstance(body, Array):
            for stmt in dir(body):
                if isinstance(body[stmt], AST_Scope):
                    continue

                # don't invade nested scopes
                if isinstance(body[stmt], AST_Definitions):
                    body[stmt].definitions.forEach(def(vardef):
                        vars.push(vardef.name.name)
                    )

                [ "body", "alternative" ].forEach(def(option):
                    nonlocal vars
                    opt = body[stmt][option]
                    if opt:
                        vars = vars.concat(scan_for_nonlocal_defs(opt))

                )

        elif body.body:
            vars = vars.concat(scan_for_nonlocal_defs(body.body))
            if body.alternative:
                vars = vars.concat(scan_for_nonlocal_defs(body.alternative))


        return vars

    def finalize_import(imp):
        if imp.body:
            classes = scan_for_classes(imp.body.body)
            for c in dir(classes):
                if isinstance(classes[c], ModuleTreeNode):
                    S.module_tree[c] = classes[c]
                else:
                    S.classes[0][c] = classes[c]

        key = ""
        while isinstance(imp, AST_Dot):
            key = "." + imp.property + key
            imp = imp.expression

        key = imp.name + key
        IMPORTED[key] = True
        return imp

    statement = embed_tokens(def():
        if is_("operator", "/") or is_("operator", "/="):
            S.peeked = None
            S.token = S.input(S.token.value.substr(1))

        tmp_ = S.token.type
        if tmp_ == "string":
            dir = S.in_directives
            stat = simple_statement()
            # XXXv2: decide how to fix directives
            if dir and isinstance(stat.body, AST_String) and not is_("punc", ","):
                return new AST_Directive({
                    value: stat.body.value
                })

            return stat
        elif tmp_ == "num" or tmp_ == "regexp" or tmp_ == "operator" or tmp_ == "atom":
            return simple_statement()
        elif tmp_ == "punc":
            tmp_ = S.token.value
            if tmp_ == ":":
                return new AST_BlockStatement({
                    start: S.token,
                    body: block_(),
                    end: prev()
                })
            elif tmp_ == "{" or tmp_ == "[" or tmp_ == "(":
                return simple_statement()
            elif tmp_ == ";":
                next()
                return new AST_EmptyStatement()
            else:
                unexpected()
        elif tmp_ == "name":
            return (is_token(peek(), "punc", ":") ? labeled_statement() : simple_statement())
        elif tmp_ == "keyword":
            tmp_ = S.token.value
            next()
            if tmp_ == "break":
                return break_cont(AST_Break)
            elif tmp_ == "continue":
                return break_cont(AST_Continue)
            elif tmp_ == "debugger":
                semicolon()
                return new AST_Debugger()
            elif tmp_ == "do":
                return new AST_Do({
                    body: in_loop(statement),
                    condition: def():
                        expect(".")
                        expect_token("keyword", "while")
                        tmp = expression(True)
                        semicolon()
                        return tmp
                    .call(this)
                })
            elif tmp_ == "while":
                return new AST_While({
                    condition: expression(True),
                    body: in_loop(statement)
                })
            elif tmp_ == "for":
                return for_()
            elif tmp_ == "from":
                return finalize_import(from_import_())
            elif tmp_ == "import":
                return finalize_import(import_())
            elif tmp_ == "require":
                return require_()
            elif tmp_ == "class":
                BASELIB["extends"] = True
                if options.auto_bind:
                    BASELIB["rebind_all"] = True
                return class_()
            elif tmp_ == "module":
                return module_()
            elif tmp_ == "def":
                start = prev()
                func = function_(S.in_class.slice(-1)[0])
                func.start = start
                func.end = prev()
                chain = subscripts(func, True)
                if chain == func:
                    return func
                else:
                    return new AST_SimpleStatement({
                        start: start,
                        body: chain,
                        end: prev()
                    })
            elif tmp_ == "if":
                return if_()
            elif tmp_ == "pass":
                semicolon()
                return new AST_EmptyStatement()
            elif tmp_ == "return":
                if S.in_function == 0:
                    croak("'return' outside of function")

                return new AST_Return({
                    value: (is_("punc", ";") ?
                        def():
                            semicolon()
                            return None
                        .call(this) : (can_insert_semicolon() ? None
                            : def():
                                tmp = expression(True)
                                semicolon()
                                return tmp
                            .call(this)
                        )
                    )
                })
            elif tmp_ == "switch":
                return new AST_Switch({
                    expression: parenthesised(),
                    body: in_loop(switch_body_)
                })
            elif tmp_ == "raise":
                if S.token.nlb:
                    return new AST_Throw({
                        value: new AST_SymbolCatch({
                            name: "_$rapyd$_Exception"
                        })
                    })

                tmp = expression(True)
                semicolon()
                return new AST_Throw({
                    value: tmp
                })
            elif tmp_ == "try":
                return try_()
            elif tmp_ == "nonlocal":
                tmp = nonlocal_()
                semicolon()
                return tmp
            elif tmp_ == "const":
                tmp = const_()
                semicolon()
                return tmp
            elif tmp_ == "with":
                return new AST_With({
                    expression: parenthesised(),
                    body: statement()
                })
            else:
                unexpected()
    )

    def labeled_statement():
        label = as_symbol(AST_Label)
        if find_if(def(l):
            return l.name == label.name
        , S.labels):
            # ECMA-262, 12.12: An ECMAScript program is considered
            # syntactically incorrect if it contains a
            # LabelledStatement that is enclosed by a
            # LabelledStatement with the same Identifier as label.
            croak("Label " + label.name + " defined twice")

        expect(":")
        S.labels.push(label)
        stat = statement()
        S.labels.pop()
        return new AST_LabeledStatement({
            body: stat,
            label: label
        })

    def simple_statement(tmp):
        tmp = expression(True)
        semicolon()
        return new AST_SimpleStatement({
            body: tmp
        })

    def break_cont(type):
        label = None
        if not can_insert_semicolon():
            label = as_symbol(AST_LabelRef, True)

        if label != None:
            if not find_if(def(l):
                return l.name == label.name
            , S.labels):
                croak("Undefined label " + label.name)

        elif S.in_loop == 0:
            croak(type.TYPE + " not inside a loop or switch")

        semicolon()
        return new type({
            label: label
        })

    def for_(list_comp):
        #        expect("(");
        init = None
        if not is_("punc", ";"):
            init = expression(True, True)
            # standardize AST_Seq into array now for consistency
            if isinstance(init, AST_Seq):
                tmp = []
                iter = init
                while iter and iter.car:
                    tmp.push(iter.car)
                    iter = iter.cdr

                tmp.push(iter)
                init = new AST_Array({
                    start: init.start,
                    elements: tmp,
                    end: init.end
                })

            if is_("operator", "in"):
                if isinstance(init, AST_Var) and init.definitions.length > 1:
                    croak("Only one variable declaration allowed in for..in loop")

                next()
                return for_in(init, list_comp)


        unexpected()

    def for_in(init, list_comp):
        lhs = (isinstance(init, AST_Var) ? init.definitions[0].name : None)
        obj = expression(True)
        #        expect(")");
        if list_comp:
            return {
                init: init,
                name: lhs,
                object: obj
            }

        return new AST_ForIn({
            init: init,
            name: lhs,
            object: obj,
            body: in_loop(statement)
        })

    # scan function/class body for nested class declarations
    def scan_for_classes(body):
        #        var classes = {};
        classes = new ModuleTreeNode()
        for i in dir(body):
            stmt = body[i]
            if isinstance(stmt, AST_Class):
                classes[stmt.name.name] = {
                    "static": stmt.static,
                    bound: stmt.bound
                }
            elif isinstance(stmt, AST_Module):
                classes[stmt.name.name] = scan_for_classes(stmt.body)
        return classes

    def get_class_in_scope(expr):
        if isinstance(expr, AST_SymbolRef):
            # check Native JS classes
            if NATIVE_CLASSES.hasOwnProperty(expr.name):
                return NATIVE_CLASSES[expr.name]

            # traverse in reverse to check local variables first
            for s in range(S.classes.length-1, -1, -1):
                if S.classes[s].hasOwnProperty(expr.name):
                    return S.classes[s][expr.name]

        elif isinstance(expr, AST_Dot):
            referenced_path = []
            # this one is for detecting classes inside modules and eventually nested classes
            while isinstance(expr, AST_Dot):
                referenced_path.unshift(expr.property)
                expr = expr.expression

            if isinstance(expr, AST_SymbolRef):
                referenced_path.unshift(expr.name)
                # now 'referenced_path' should contain the full path of potential class
                # Due to scoping that prefers local-most variables, there are multiple ways a class could be referenced.
                # To emulate this behavior, we'd need to travel into inner-most scope first and from there keep traveling
                # outward, while testing for existance of the given object chain in each scope level.
                current_scope = S.module_stack.slice()
                current_scope.unshift("")
                # global scope
                while current_scope.length:
                    # navigate to correct location in the module
                    visible_scope = S.module_tree
                    current_scope.forEach(def(module__):
                        nonlocal visible_scope
                        if module__ in visible_scope:
                            visible_scope = visible_scope[module__]
                    )
                    # now try to find the given path in the tree
                    traversed_path = referenced_path.slice()
                    while traversed_path and visible_scope[traversed_path[0]]:
                        visible_scope = visible_scope[traversed_path[0]]
                        traversed_path.shift()

                    # we arrived to the end of the path, if visible_scope points to a class, then this call is for a class
                    if not traversed_path.length:
                        if not isinstance(visible_scope, ModuleTreeNode):
                            return visible_scope
                        else:
                            return False

                    current_scope.pop()
        return False

    def module_pathname(name):
        file_ = ""
        while isinstance(name, AST_Dot):
            file_ = "/" + name.property + file_
            name = name.expression
            
        return name.name + file_

    find_module_realpath = def(name):
        if name in options.js_imports:
            return name # No need to validate module exists in search path

        search_paths = options.search_paths
        for path in search_paths:
            if path and path != "":
                fullpath = path + "/" + name
            else:
                fullpath = options.basedir + "/" + name
            
            if options.fs.existsSync(fullpath + options.ext):
                return fullpath

        raise Error("Cannot import: " + name)

    read_module_contents = def(fullpath):
    
        options_ = {
            filename: fullpath,
            toplevel: None,
            readfile: options.readfile,
            fs: options.fs,
            basedir: options.basedir,
            ext: options.ext,
            amd: options.amd,
            js_imports: options.js_imports,
            search_paths: options.search_paths
        }
        return parse(options.readfile(fullpath + options.ext, "utf-8"), options_)

    import_ = def():
        name = expression(False)
        path = module_pathname(name)
        contents = None
        fullpath = find_module_realpath(path)
        if !options.amd:
            contents = read_module_contents(fullpath)

        return new AST_Import({
            module: name,
            path: fullpath,
            argnames: None,
            body: contents,
            variables: def():
                # detect publically-seen variables
                return scan_for_local_vars(contents, True).filter(def(element, index, arr):
                    return arr.lastIndexOf(element) is index
                )
            .call(this)
        })

    from_import_ = def():
        name = expression(False)
        expect_token("keyword", "import")
        path = module_pathname(name)
        body = None
        fullpath = find_module_realpath(path)
        if !options.amd:          
            body = read_module_contents(fullpath)

        return new AST_Import({
            module: name,
            path: fullpath,
            body: body,
            argnames: def(a):
                a.push(as_symbol(AST_SymbolVar))
                while is_("punc", ","):
                    next()
                    a.push(as_symbol(AST_SymbolVar))
                return a
            .call(this, [])
        })

    require_ = def():
        next_node = peek()
        node = expression(False)
        if not isinstance(node, AST_String):
            unexpected(node)
          
        as_name = None
        if next_node.type is "keyword" and next_node.value is "as":
            next()
            as_name = as_symbol(AST_SymbolVar)
            
        path = node.value
        return new AST_Import({
            module: node,
            path: path,
            as: as_name
        })
     
    ModuleTreeNode = def():
        pass
    # this exists to allow 'instanceof' check from within get_class_in_scope()
    module_ = def(use_name):
        name = use_name ? use_name : as_symbol(AST_SymbolDefun)
        if not name:
            unexpected()

        definition = new AST_Module({
            name: name,
            body: def():
                # navigate to correct location in the module tree and append the module
                module_tree = S.module_tree
                S.module_stack.forEach(def(module__):
                    nonlocal module_tree
                    module_tree = module_tree[module__]
                )
                module_tree[name.name] = new ModuleTreeNode()
                S.module_stack.push(name.name)
                a = block_()
                S.module_stack.pop()
                return a
            .call(this),
            external: reserved_decorator(S, "external"), # detect external modules
            decorators: def():
                d = []
                S.decorators.forEach(def(decorator):
                    d.push(new AST_Decorator({
                        name: decorator
                    }))
                )
                S.decorators = []
                return d
            .call(this),
            variables: [],
            localvars: []
        })
        # detect publically-seen variables
        definition.variables = scan_for_local_vars(definition.body, True).filter(def(element, index, arr):
            return arr.lastIndexOf(element) is index
        )
        definition.localvars = scan_for_local_vars(definition.body, False).filter(def(element, index, arr):
            return arr.lastIndexOf(element) is index
        ).map(def(element):
            return new_symbol(AST_SymbolVar, element)
        )
        return definition

    class_ = def():
        name = as_symbol(AST_SymbolDefun)
        if not name:
            unexpected()

        
        class_details = {
            "static": [],
            bound: {}
        }
        definition = new AST_Class({
            name: name,
            parent: def():
                if is_("punc", "("):
                    next()
                    a = expr_atom(False)
                    expect(")")
                    return a
                else:
                    return None
            .call(this),
            modules: S.module_stack.slice(),
            localvars: [],
            "static": class_details.static,
            external: reserved_decorator(S, "external"), # detect external classes
            public:  reserved_decorator(S, "public"), # detect public classes
            bound: class_details.bound,
            decorators: def():
                d = []
                S.decorators.forEach(def(decorator):
                    d.push(new AST_Decorator({
                        name: decorator
                    }))
                )
                S.decorators = []
                return d
            .call(this),
            body: def(loop, labels):
                # navigate to correct location in the module tree and append the class
                module_tree = S.module_tree
                S.module_stack.forEach(def(module__):
                    nonlocal module_tree
                    module_tree = module_tree[module__]
                )
                module_tree[name.name] = class_details
                S.in_class.push(name.name)
                S.classes[S.classes.length - 1][name.name] = class_details
                S.classes.push({})
                S.in_function += 1
                S.in_directives = True
                S.in_loop = 0
                S.labels = []
                a = block_()
                S.in_function -= 1
                S.classes.pop()
                S.in_class.pop()
                S.in_loop = loop
                S.labels = labels
                return a
            .call(this, S.in_loop, S.labels)
        })
        # find the constructor
        for i in dir(definition.body):
            stmt = definition.body[i]
            if isinstance(stmt, AST_Method) and stmt.name.name == "__init__":
                definition.init = stmt
                break
        return definition

    function_ = def(in_class, ctor):
        is_accessor = ctor is AST_Accessor
        name = (is_("name") ? as_symbol((in_class ? AST_SymbolDefun : (is_accessor ? AST_SymbolAccessor : AST_SymbolLambda))) : (is_accessor and (is_("string") or is_("num")) ? as_atom_node() : None))
        if in_class and not name:
            unexpected()

        staticmethod = False
        is_public = reserved_decorator(S, "public") # detect public functions
#        if in_class and is_public:
#            unexpected() # Do not support concept of non-public methods in a class

        if in_class:
            staticmethod = reserved_decorator(S, "staticmethod")
            if staticmethod:
                S.classes[S.classes.length - 2][in_class].static.push(name.name)
            elif name.name != "__init__" and options.auto_bind:
                BASELIB["bind"] = True
                S.classes[S.classes.length - 2][in_class].bound[name.name] = True

        expect("(")
        if not ctor:
            ctor = in_class ? AST_Method : AST_Function

        definition = new ctor({
            name: name,
            argnames: def(a):
                defaults = {}
                first = True
                while not is_("punc", ")"):
                    if first:
                        first = False
                    else:
                        expect(",")
                    if a.starargs:
                        token_error(prev(), "Can't define multiple *args in function definition")
                    elif is_("operator", "*"):
                        next()
                        a.starargs = as_symbol(AST_SymbolFunarg)
                    else:
                        a.push(as_symbol(AST_SymbolFunarg))
                        if is_("operator", "="):
                            val = prev().value
                            next()
                            defaults[val] = expression(False)

                next()
                a.defaults = defaults
                return a
            .call(this, []),
            localvars: [],
            decorators: def():
                d = []
                S.decorators.forEach(def(decorator):
                    d.push(new AST_Decorator({
                        name: decorator
                    }))
                )
                S.decorators = []
                return d
            .call(this),
            body: def(loop, labels):
                S.in_class.push(False)
                S.classes.push({})
                S.in_function += 1
                S.in_directives = True
                S.in_loop = 0
                S.labels = []
                a = block_()
                S.in_function -= 1
                S.classes.pop()
                S.in_class.pop()
                S.in_loop = loop
                S.labels = labels
                return a
            .call(this, S.in_loop, S.labels)
        })
        if isinstance(definition, AST_Method):
            definition.static = staticmethod
            
        if isinstance(definition, AST_Function):
            definition.public = is_public

        # detect local variables, strip function arguments
        assignments = scan_for_local_vars(definition.body, False).filter(def(element, index, arr):
            return arr.lastIndexOf(element) is index
        )
        for i in range(assignments.length):
            for j in range(definition.argnames.length+1):
                if j == definition.argnames.length:
                    definition.localvars.push(new_symbol(AST_SymbolVar, assignments[i]))
                elif j < definition.argnames.length and assignments[i] == definition.argnames[j].name:
                    break

        nonlocals = scan_for_nonlocal_defs(definition.body)
        nonlocals.forEach(def(variable):
            for i in dir(definition.localvars).reverse():
                if definition.localvars[i].name == variable:
                    definition.localvars.splice(i, 1)
        )
        return definition

    def if_():
        cond = expression(True)
        body = statement()
        belse = None
        if is_("keyword", "elif") or is_("keyword", "else"):
            if is_("keyword", "else"):
                next()
            else:
                S.token.value = "if"
            # effectively converts 'elif' to 'else if'
            belse = statement()

        return new AST_If({
            condition: cond,
            body: body,
            alternative: belse
        })

    def block_():
        expect(":")
        a = []
        if not S.token.nlb:
            while not S.token.nlb:
                if is_("eof"):
                    unexpected()
                a.push(statement())
        else:
            while not is_("punc", "}"):
                if is_("eof"):
                    unexpected()
                a.push(statement())
            next()
        return a

    def switch_body_():
        expect("{")
        a = []
        cur = None
        branch = None

        while not is_("punc", "}"):
            if is_("eof"):
                unexpected()

            if is_("keyword", "case"):
                if branch:
                    branch.end = prev()

                cur = []
                branch = new AST_Case({
                    start: (tmp = S.token, next(), tmp),
                    expression: expression(True),
                    body: cur
                })
                a.push(branch)
                expect(":")
            elif is_("keyword", "default"):
                if branch:
                    branch.end = prev()

                cur = []
                branch = new AST_Default({
                    start: (tmp = S.token, next(), expect(":"), tmp),
                    body: cur
                })
                a.push(branch)
            else:
                if not cur:
                    unexpected()
                cur.push(statement())

        if branch:
            branch.end = prev()
        next()
        return a

    def try_():
        body = block_()
        bcatch = []
        bfinally = None
        while is_("keyword", "except"):
            start = S.token
            next()
            exceptions = []
            if not is_("punc", ":") and not is_("keyword", "as"):
                exceptions.push(as_symbol(AST_SymbolVar))
                while is_("punc", ","):
                    next()
                    exceptions.push(as_symbol(AST_SymbolVar))

            name = None
            if is_("keyword", "as"):
                next()
                name = as_symbol(AST_SymbolCatch)

            bcatch.push(new AST_Except({
                start: start,
                argname: name,
                errors: exceptions,
                body: block_(),
                end: prev()
            }))

        if is_("keyword", "finally"):
            start = S.token
            next()
            bfinally = new AST_Finally({
                start: start,
                body: block_(),
                end: prev()
            })

        if not bcatch.length and not bfinally:
            croak("Missing except/finally blocks")

        return new AST_Try({
            body: body,
            bcatch: (bcatch.length ? new AST_Catch({
                body: bcatch
            }) : None),
            bfinally: bfinally
        })

    def vardefs(no_in, in_const):
        a = []
        while True:
            a.push(new AST_VarDef({
                start: S.token,
                name: as_symbol((in_const ? AST_SymbolConst : AST_SymbolVar)),
                value: (is_("operator", "=") ? (next(), expression(False, no_in)) : None),
                end: prev()
            }))
            if not is_("punc", ","):
                break
            next()

        return a

    def new_vardefs(no_in, in_const):
        a = []
        while True:
            a.push(new AST_VarDef({
                start: S.token,
                name: new_symbol((in_const ? AST_SymbolConst : AST_SymbolVar)),
                value: (is_("operator", "=") ? (next(), expression(False, no_in)) : None),
                end: prev()
            }))
            if not is_("punc", ","):
                break

            next()
        return a

    nonlocal_ = def(no_in):
        return new AST_Var({
            start: prev(),
            definitions: vardefs(no_in, False),
            end: prev()
        })

    const_ = def():
        return new AST_Const({
            start: prev(),
            definitions: vardefs(False, True),
            end: prev()
        })

    new_ = def():
        start = S.token
        expect_token("operator", "new")
        newexp = expr_atom(False)

        if is_("punc", "("):
            next()
            args = expr_list(")")
        else:
            args = []

        return subscripts(new AST_New({
            start: start,
            expression: newexp,
            args: args,
            end: prev()
        }), True)

    def as_atom_node():
        tok = S.token
        tmp_ = tok.type
        if tmp_ == "name":
            return as_symbol(AST_SymbolRef)
        elif tmp_ == "num":
            ret = new AST_Number({
                start: tok,
                end: tok,
                value: tok.value
            })
        elif tmp_ == "string":
            ret = new AST_String({
                start: tok,
                end: tok,
                value: tok.value
            })
        elif tmp_ == "regexp":
            ret = new AST_RegExp({
                start: tok,
                end: tok,
                value: tok.value
            })
        elif tmp_ == "atom":
            tmp__ = tok.value
            if tmp__ == "False":
                ret = new AST_False({
                    start: tok,
                    end: tok
                })
            elif tmp__ == "True":
                ret = new AST_True({
                    start: tok,
                    end: tok
                })
            elif tmp__ == "None":
                ret = new AST_Null({
                    start: tok,
                    end: tok
                })

        next()
        return ret

    expr_atom = def(allow_calls):
        if is_("operator", "new"):
            return new_()

        start = S.token
        if is_("punc"):
            tmp_ = start.value
            if tmp_ == "(":
                next()
                ex = expression(True)
                ex.start = start
                ex.end = S.token
                expect(")")
                return subscripts(ex, allow_calls)
            elif tmp_ == "[":
                return subscripts(array_(), allow_calls)
            elif tmp_ == "{":
                return subscripts(object_(), allow_calls)

            unexpected()

        if is_("keyword", "class"):
            next()
            cls = class_()
            cls.start = start
            cls.end = prev()
            return subscripts(cls, allow_calls)

        if is_("keyword", "def"):
            next()
            func = function_(False)
            func.start = start
            func.end = prev()
            return subscripts(func, allow_calls)

        if ATOMIC_START_TOKEN[S.token.type]:
            return subscripts(as_atom_node(), allow_calls)

        unexpected()

    def expr_list(closing, allow_trailing_comma, allow_empty, func_call):
        first = True
        a = []
        saw_starargs = False
        while not is_("punc", closing):
            if saw_starargs:
                token_error(prev(), "*args must be the last argument in a function call")

            if first:
                first = False
            else:
                expect(",")
            if allow_trailing_comma and is_("punc", closing):
                break

            if is_("operator", "*") and func_call:
                saw_starargs = True
                next()

            if is_("punc", ",") and allow_empty:
                a.push(new AST_Hole({
                    start: S.token,
                    end: S.token
                }))
            else:
                a.push(expression(False))

        if func_call:
            tmp = []
            tmp.kwargs = []
            for i, arg in enumerate(a):
                if isinstance(arg, AST_Assign):
                    tmp.kwargs.push([arg.left, arg.right])
                else:
                    tmp.push(arg)
            a = tmp

        next()
        if saw_starargs:
            a.starargs = True
        return a

    def func_call_list():
        return expr_list(")", False, False, True)

    array_ = embed_tokens(def():
        expect("[")
        expr = []
        if not is_("punc", "]"):
            expr.push(expression(False))
            if is_("keyword", "for"):
                # list comprehension
                next()
                forloop = for_(True)
                ret = new AST_ListComprehension({
                    statement: expr[0],
                    init: forloop.init,
                    name: forloop.name,
                    object: forloop.object,
                    condition: (is_("punc", "]") ? None : (expect_token("keyword", "if"), expression(True)))
                })
                expect("]")
                return ret

            if is_("operator", "til"):
                next()
                expr.push(expression(False))
                ret = subscripts(new AST_Call({
                    start: S.token,
                    expression: new AST_SymbolRef({
                        name: "range"
                    }),
                    args: expr,
                    end: prev()
                }), True)
                expect("]")
                return ret
            elif is_("operator", "to"):
                next()
                expr.push(new AST_Binary({
                    left: expression(False),
                    operator: "+",
                    right: new AST_Number({
                        value: 1
                    })
                }))
                ret = subscripts(new AST_Call({
                    start: S.token,
                    expression: new AST_SymbolRef({
                        name: "range"
                    }),
                    args: expr,
                    end: prev()
                }), True)
                expect("]")
                return ret
            elif not is_("punc", "]"):
                expect(",")

        return new AST_Array({
            elements: expr.concat(expr_list("]", not options.strict, True))
        })
    )
    object_ = embed_tokens(def():
        expect("{")
        first = True
        a = []
        while not is_("punc", "}"):
            if first:
                first = False
            else:
                expect(",")
            if not options.strict and is_("punc", "}"):
                # allow trailing comma
                break

            start = S.token
            type = start.type
            key = as_property_name()
            name = key.value
            quoted = (key.type == "string" ? True : False)
            if type == "name" and not is_("punc", ":"):
                if name == "get":
                    a.push(new AST_ObjectGetter({
                        start: start,
                        key: name,
                        quoted: quoted,
                        value: function_(False, AST_Accessor),
                        end: prev()
                    }))
                    continue

                if name == "set":
                    a.push(new AST_ObjectSetter({
                        start: start,
                        key: name,
                        quoted: quoted,
                        value: function_(False, AST_Accessor),
                        end: prev()
                    }))
                    continue

            expect(":")
            a.push(new AST_ObjectKeyVal({
                start: start,
                key: name,
                quoted: quoted,
                value: expression(False),
                end: prev()
            }))

        next()
        return new AST_Object({
            properties: a
        })
    )

    def as_property_name():
        tmp = S.token
        next()
        tmp_ = tmp.type
        if tmp_ == "num" or tmp_ == "string" or tmp_ == "name" or tmp_ == "operator" or tmp_ == "keyword" or tmp_ == "atom":
            return tmp
        else:
            unexpected()

    def as_name():
        tmp = S.token
        next()
        tmp_ = tmp.type
        if tmp_ == "name" or tmp_ == "operator" or tmp_ == "keyword" or tmp_ == "atom":
            return tmp.value
        else:
            unexpected()

    def as_symbol(type, noerror):
        if not is_("name"):
            if not noerror:
                croak("Name expected")
            return None

        name = S.token.value
        sym = new ((name == "this" ? AST_This : type))({
            name: JS("String(S.token.value)"),
            start: S.token,
            end: S.token
        })
        next()
        return sym

    # for generating/inserting a new symbol
    def new_symbol(type, name):
        sym = new ((name == "this" ? AST_This : type))({
            name: JS("String(name)"),
            start: None,
            end: None
        })
        return sym

    def is_static_method(cls, method):
        if cls.static and cls.static.indexOf(method) != -1:
            return True
        else:
            return False

    subscripts = def(expr, allow_calls):
        start = expr.start
        if is_("punc", "."):
            next()
            return subscripts(new AST_Dot({
                start: start,
                expression: expr,
                property: as_name(),
                end: prev()
            }), allow_calls)

        if is_("punc", "[") and not S.token.nlb:
            next()
            slice_bounds = []
            is_slice = False
            if is_("punc", ":"):
                # slice [:n]
                slice_bounds.push(new AST_Number({
                    value: 0
                }))
            else:
                slice_bounds.push(expression(False))

            if is_("punc", ":"):
                # slice [n:m?]
                is_slice = True
                next()
                if not is_("punc", "]"):
                    slice_bounds.push(expression(False))

            expect("]")
            if is_slice:
                return subscripts(new AST_Call({
                    start: start,
                    expression: new AST_Dot({
                        start: start,
                        expression: expr,
                        property: "slice",
                        end: prev()
                    }),
                    args: slice_bounds,
                    end: prev()
                }), allow_calls)
            else:
                return subscripts(new AST_Sub({
                    start: start,
                    expression: expr,
                    property: slice_bounds[0],
                    end: prev()
                }), allow_calls)

        if allow_calls and is_("punc", "(") and not S.token.nlb:
            next()
            if isinstance(expr, AST_SymbolRef) and expr.name == "JS":
                str_ = expression(False)
                if not (isinstance(str_, AST_String)):
                    token_error(prev(), "Compile-time function JS() can't process variables or expressions")

                ret = new AST_Verbatim({
                    start: start,
                    value: str_.value,
                    end: prev()
                })
                expect(")")
                return ret
            elif get_class_in_scope(expr):
                # this is an object being created using a class
                return subscripts(new AST_New({
                    start: start,
                    expression: expr,
                    args: func_call_list(),
                    end: prev()
                }), True)
            else:
                if isinstance(expr, AST_Dot):
                    c = get_class_in_scope(expr.expression)

                if c:
                    # generate class call
                    funcname = expr
                    if funcname.property == "__init__":
                        funcname.property = "constructor"

                    return subscripts(new AST_ClassCall({
                        start: start,
                        "class": expr.expression,
                        method: funcname.property,
                        "static": is_static_method(c, funcname.property),
                        args: func_call_list(),
                        end: prev()
                    }), True)
                elif isinstance(expr, AST_SymbolRef):
                    tmp_ = expr.name
                    if tmp_ == "abs"
                    or tmp_ == "bind"
                    or tmp_ == "rebind_all"
                    or tmp_ == "dir"
                    or tmp_ == "enumerate"
                    or tmp_ == "len"
                    or tmp_ == "mixin"
                    or tmp_ == "print"
                    or tmp_ == "range"
                    or tmp_ == "reversed"
                    or tmp_ == "getattr"
                    or tmp_ == "setattr"
                    or tmp_ == "hasattr":
                        BASELIB[expr.name] = True
                        # NOTE: there is intentionally no return here, we want these functions to go through regular logic
                        # after they trigger the appropriate baselib flag
                    elif tmp_ == "type":
                        return new AST_UnaryPrefix({
                            start: start,
                            operator: "typeof",
                            expression: func_call_list()[0],
                            end: prev()
                        })
                    elif tmp_ == "isinstance":
                        args = func_call_list()
                        return new AST_Binary({
                            start: start,
                            operator: "instanceof",
                            left: args[0],
                            right: args[1],
                            end: prev()
                        })

                return subscripts(new AST_Call({
                    start: start,
                    expression: expr,
                    args: func_call_list(),
                    end: prev()
                }), True)

        return expr

    maybe_unary = def(allow_calls):
        start = S.token
        if is_("operator") and UNARY_PREFIX(start.value):
            t = peek()
            next()
            if start.value == "@":
                if is_("name") and (peek().value == "@" or peek().value == "def" or peek().value == "class" or peek().value == "module"
                                    or t.value == "public" ):
                    S.decorators.push(S.token.value)
                    next()
                    return new AST_EmptyStatement()
                else:
                    unexpected()

            ex = make_unary(AST_UnaryPrefix, start.value, maybe_unary(allow_calls))
            ex.start = start
            ex.end = prev()
            return ex

        val = expr_atom(allow_calls)
        while is_("operator") and UNARY_POSTFIX(S.token.value) and not S.token.nlb:
            val = make_unary(AST_UnaryPostfix, S.token.value, val)
            val.start = start
            val.end = S.token
            next()
        return val

    def make_unary(ctor, op, expr):
        if op == "++" or op == "--":
            croak("Invalid operator «" + op + "»")
        return new ctor({
            operator: op,
            expression: expr
        })

    expr_op = def(left, min_prec, no_in):
        op = (is_("operator") ? S.token.value : None)
        not_in = False
        if op == "!" and peek().type == "operator" and peek().value == "in":
            next()
            op = "in"
            not_in = True

        if op == "in":
            if no_in:
                op = None
            else:
                BASELIB[op] = True

        prec = (op != None ? PRECEDENCE[op] : None)
        if prec != None and prec > min_prec:
            next()
            right = expr_op(maybe_unary(True), prec, no_in)
            ret = new AST_Binary({
                start: left.start,
                left: left,
                operator: op,
                right: right,
                end: right.end
            })
            if not_in:
                ret = new AST_UnaryPrefix({
                    start: left.start,
                    operator: "!",
                    expression: ret,
                    end: right.end
                })
            return expr_op(ret, min_prec, no_in)
        return left

    def expr_ops(no_in):
        return expr_op(maybe_unary(True), 0, no_in)

    maybe_conditional = def(no_in):
        start = S.token
        expr = expr_ops(no_in)
        if is_("operator", "?"):
            next()
            yes = expression(False)
            expect(":")
            return new AST_Conditional({
                start: start,
                condition: expr,
                consequent: yes,
                alternative: expression(False, no_in),
                end: peek()
            })
        return expr

    def is_assignable(expr):
        if not options.strict:
            return True

        tmp_ = expr[0] + ""
        if tmp_ == "dot" or tmp_ == "sub" or tmp_ == "new" or tmp_ == "call":
            return True
        elif tmp_ == "name":
            return expr[1] != "this"

    maybe_assign = def(no_in):
        start = S.token
        is_public = reserved_decorator(S, "public")
        left = maybe_conditional(no_in)
        left.public = is_public
        val = S.token.value
        if is_("operator") and ASSIGNMENT(val):
            if is_assignable(left):
                next()
                return new AST_Assign({
                    start: start,
                    left: left,
                    operator: val,
                    right: maybe_assign(no_in),
                    end: prev()
                })
            croak("Invalid assignment")
        return left

    expression = def(commas, no_in):
        # if there is an assignment, we want the sequences to pivot
        # around it to allow for tuple packing/unpacking
        start = S.token
        expr = maybe_assign(no_in)
        if commas:
            left = [ expr ]
            right = []
            while is_("punc", ",") and not peek().nlb:
                next()
                if isinstance(expr, AST_Assign):
                    # AST_Seq representation is ugly to decode for
                    # assignments, let's convert data to array now
                    # to avoid dealing with it
                    #                    return new AST_TupleUnpack({
                    #                        start    : start,
                    #                        elements : left,
                    #                        right    : expression(true, no_in),
                    #                        end      : peek()
                    #                    });
                    left[left.length - 1] = left.slice(-1)[0].left
                    return new AST_Assign({
                        start: start,
                        left: (left.length == 1 ? left[0] : new AST_Array({
                            elements: left
                        })),
                        operator: expr.operator,
                        right: new AST_Seq({
                            car: expr.right,
                            cdr: expression(True, no_in)
                        }),
                        end: peek()
                    })

                expr = maybe_assign(no_in)
                left.push(expr)

            # if last one was an assignment, fix it
            if left.length > 1 and isinstance(left.slice(-1)[0], AST_Assign):
                left[left.length - 1] = left.slice(-1)[0].left
                return new AST_Assign({
                    start: start,
                    left: new AST_Array({
                        elements: left
                    }),
                    operator: expr.operator,
                    right: expr.right,
                    end: peek()
                })

            return def build_seq(a):
                if a.length == 1:
                    return a[0]

                return new AST_Seq({
                    start: start,
                    car: a.shift(),
                    cdr: build_seq(a),
                    end: peek()
                })
            .call(this, left)
        return expr

    def in_loop(cont):
        S.in_loop += 1
        ret = cont()
        S.in_loop -= 1
        return ret

    return def():
        start = S.token
        body = []
        while not is_("eof"):
            body.push(statement())

        end = prev()
        toplevel = options.toplevel
        if toplevel:
            toplevel.body = toplevel.body.concat(body)
            toplevel.end = end
        else:
            toplevel = new AST_Toplevel({
                start: start,
                body: body,
                strict: def():
                    for stmt in body:
                        if isinstance(stmt, AST_Directive) and stmt.value == 'use strict':
                            return True
                    return False
                .call(this),
                end: end
            })

        assignments = scan_for_local_vars(toplevel.body, False).filter(def(element, index, arr):
            return arr.lastIndexOf(element) is index
        )
        toplevel.localvars = []
        assignments.forEach(def(item):
            toplevel.localvars.push(new_symbol(AST_SymbolVar, item))
        )
        toplevel.imports = IMPORTED
        toplevel.baselib = BASELIB
        return toplevel
    .call(this)



