"""
**********************************************************************

  A RapydScript to JavaScript compiler.
  https://github.com/atsepkov/RapydScript

  -------------------------------- (C) ---------------------------------

                       Author: Alexander Tsepkov
                         <atsepkov@pyjeon.com>
                         http://www.pyjeon.com

  Distributed under Apache 2.0 license:
    Copyright 2013 (c) Alexander Tsepkov <atsepkov@pyjeon.com>

  RapydScript source code is originally based on UglifyJS2 (covered
  by BSD license). UglifyJS2 was written by Mihai Bazon
  <mihai.bazon@gmail.com>, who is its respective copyright holder.

    Redistribution and use in source and binary forms, with or without
    modification, are permitted provided that the following conditions
    are met:

        * Redistributions of source code must retain the above
          copyright notice, this list of conditions and the following
          disclaimer.

        * Redistributions in binary form must reproduce the above
          copyright notice, this list of conditions and the following
          disclaimer in the documentation and/or other materials
          provided with the distribution.

    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDER “AS IS” AND ANY
    EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
    PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE
    LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
    PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
    PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
    THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
    TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF
    THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
    SUCH DAMAGE.

**********************************************************************
"""
"use strict"

ES6_KEYWORDS = "yield"
KEYWORDS = "as break case class const continue debugger default def del do elif else except " +
"finally for from if import in instanceof is new nonlocal pass raise return switch til to " +
"try typeof var void while with or and not" + " " + ES6_KEYWORDS


KEYWORDS_ATOM = "False None True"

RESERVED_WORDS = "abstract boolean byte char double enum export extends final float goto " +
"implements int interface long native package private protected public short static super " +
"synchronized this throws transient volatile" + " " + KEYWORDS_ATOM + " " + KEYWORDS

KEYWORDS_BEFORE_EXPRESSION = "return new del raise elif else if"

ALL_KEYWORDS = RESERVED_WORDS + " " + KEYWORDS_BEFORE_EXPRESSION

KEYWORDS = makePredicate(KEYWORDS)
ES6_KEYWORDS = makePredicate(ES6_KEYWORDS)
RESERVED_WORDS = makePredicate(RESERVED_WORDS)
KEYWORDS_BEFORE_EXPRESSION = makePredicate(KEYWORDS_BEFORE_EXPRESSION)
KEYWORDS_ATOM = makePredicate(KEYWORDS_ATOM)

NATIVE_CLASSES = {
    # javascript
    'Image': {},
    'RegExp': {},
    'Error': {},
    'Object': {
        static: [
            "assign",               # ES6
            "getOwnPropertyNames",
            "keys",
            "create",
            "defineProperty",
            "defineProperties",
            "getPrototypeOf",       # ES6
            "setPrototypeOf",       # ES6
        ]
    },
    'String': {
        static: [ "fromCharCode" ]
    },
    'Array': {
        static: [ "isArray", "from", "of" ]
    },
    'Number': {
        static: [ "isFinite", "isNaN" ]
    },
    'Function': {},
    'Date': {
        static: [ "UTC", "now", "parse" ]
    },
    'Boolean': {},
    'ArrayBuffer': {},
    'DataView': {},
    'Float32Array': {},
    'Float64Array': {},
    'Int16Array': {},
    'Int32Array': {},
    'Int8Array': {},
    'Uint16Array': {},
    'Uint32Array': {},
    'Uint8Array': {},
    'Uint8ClampedArray': {},
    'Map': {},      # ES6
    'WeakMap': {},  # ES6
    'Set': {},      # ES6
    'WeakSet': {},  # ES6

    # baselib
    "AssertionError": {},
    "IndexError": {},
    "KeyError": {},
    "TypeError": {},
    "ValueError": {},
}
COMMON_STATIC = [ "call", "apply", "bind", "toString" ]

OPERATOR_CHARS = makePredicate(characters("+-*&%=<>!?|~^@"))

RE_HEX_NUMBER = /^0x[0-9a-f]+$/i
RE_OCT_NUMBER = /^0[0-7]+$/
RE_DEC_NUMBER = /^\d*\.?\d*(?:e[+-]?\d*(?:\d\.?|\.?\d)\d*)?$/i

OPERATORS = makePredicate([
    "in",
    "instanceof",
    "typeof",
    "new",
    "void",
    "del",
    "++",
    "--",
    "+",
    "-",
    "not",
    "~",
    "&",
    "|",
    "^",
    "**",
    "*",
    "/",
    "//",
    "%",
    ">>",
    "<<",
    ">>>",
    "<",
    ">",
    "<=",
    ">=",
    "==",
    "===",
    "is",
    "!=",
    "!==",
    "?",
    "=",
    "+=",
    "-=",
    "/=",
    "//=",
    "*=",
    "%=",
    ">>=",
    "<<=",
    ">>>=",
    "|=",
    "^=",
    "&=",
    "and",
    "or",
    "til",
    "to",
    "@"
])

OP_MAP = {
    'or': "||",
    'and': "&&",
    'not': "!",
    'del': "delete",
    'None': "null",
    'is': "===",
    '==': "===",
    '!=': "!=="
}

WHITESPACE_CHARS = makePredicate(characters(" \u00a0\n\r\t\f\u000b\u200b\u180e\u2000\u2001\u2002\u2003\u2004\u2005\u2006\u2007\u2008\u2009\u200a\u202f\u205f\u3000"));

PUNC_BEFORE_EXPRESSION = makePredicate(characters("[{(,.;:"))

PUNC_CHARS = makePredicate(characters("[]{}(),;:"))

REGEXP_MODIFIERS = makePredicate(characters("gmsiy"))

# -----[ Tokenizer ]-----
# regexps adapted from http://xregexp.com/plugins/#unicode
UNICODE = {  # {{{
    letter: RegExp("[\\u0041-\\u005A\\u0061-\\u007A\\u00AA\\u00B5\\u00BA\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02C1\\u02C6-\\u02D1\\u02E0-\\u02E4\\u02EC\\u02EE\\u0370-\\u0374\\u0376\\u0377\\u037A-\\u037D\\u0386\\u0388-\\u038A\\u038C\\u038E-\\u03A1\\u03A3-\\u03F5\\u03F7-\\u0481\\u048A-\\u0523\\u0531-\\u0556\\u0559\\u0561-\\u0587\\u05D0-\\u05EA\\u05F0-\\u05F2\\u0621-\\u064A\\u066E\\u066F\\u0671-\\u06D3\\u06D5\\u06E5\\u06E6\\u06EE\\u06EF\\u06FA-\\u06FC\\u06FF\\u0710\\u0712-\\u072F\\u074D-\\u07A5\\u07B1\\u07CA-\\u07EA\\u07F4\\u07F5\\u07FA\\u0904-\\u0939\\u093D\\u0950\\u0958-\\u0961\\u0971\\u0972\\u097B-\\u097F\\u0985-\\u098C\\u098F\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BD\\u09CE\\u09DC\\u09DD\\u09DF-\\u09E1\\u09F0\\u09F1\\u0A05-\\u0A0A\\u0A0F\\u0A10\\u0A13-\\u0A28\\u0A2A-\\u0A30\\u0A32\\u0A33\\u0A35\\u0A36\\u0A38\\u0A39\\u0A59-\\u0A5C\\u0A5E\\u0A72-\\u0A74\\u0A85-\\u0A8D\\u0A8F-\\u0A91\\u0A93-\\u0AA8\\u0AAA-\\u0AB0\\u0AB2\\u0AB3\\u0AB5-\\u0AB9\\u0ABD\\u0AD0\\u0AE0\\u0AE1\\u0B05-\\u0B0C\\u0B0F\\u0B10\\u0B13-\\u0B28\\u0B2A-\\u0B30\\u0B32\\u0B33\\u0B35-\\u0B39\\u0B3D\\u0B5C\\u0B5D\\u0B5F-\\u0B61\\u0B71\\u0B83\\u0B85-\\u0B8A\\u0B8E-\\u0B90\\u0B92-\\u0B95\\u0B99\\u0B9A\\u0B9C\\u0B9E\\u0B9F\\u0BA3\\u0BA4\\u0BA8-\\u0BAA\\u0BAE-\\u0BB9\\u0BD0\\u0C05-\\u0C0C\\u0C0E-\\u0C10\\u0C12-\\u0C28\\u0C2A-\\u0C33\\u0C35-\\u0C39\\u0C3D\\u0C58\\u0C59\\u0C60\\u0C61\\u0C85-\\u0C8C\\u0C8E-\\u0C90\\u0C92-\\u0CA8\\u0CAA-\\u0CB3\\u0CB5-\\u0CB9\\u0CBD\\u0CDE\\u0CE0\\u0CE1\\u0D05-\\u0D0C\\u0D0E-\\u0D10\\u0D12-\\u0D28\\u0D2A-\\u0D39\\u0D3D\\u0D60\\u0D61\\u0D7A-\\u0D7F\\u0D85-\\u0D96\\u0D9A-\\u0DB1\\u0DB3-\\u0DBB\\u0DBD\\u0DC0-\\u0DC6\\u0E01-\\u0E30\\u0E32\\u0E33\\u0E40-\\u0E46\\u0E81\\u0E82\\u0E84\\u0E87\\u0E88\\u0E8A\\u0E8D\\u0E94-\\u0E97\\u0E99-\\u0E9F\\u0EA1-\\u0EA3\\u0EA5\\u0EA7\\u0EAA\\u0EAB\\u0EAD-\\u0EB0\\u0EB2\\u0EB3\\u0EBD\\u0EC0-\\u0EC4\\u0EC6\\u0EDC\\u0EDD\\u0F00\\u0F40-\\u0F47\\u0F49-\\u0F6C\\u0F88-\\u0F8B\\u1000-\\u102A\\u103F\\u1050-\\u1055\\u105A-\\u105D\\u1061\\u1065\\u1066\\u106E-\\u1070\\u1075-\\u1081\\u108E\\u10A0-\\u10C5\\u10D0-\\u10FA\\u10FC\\u1100-\\u1159\\u115F-\\u11A2\\u11A8-\\u11F9\\u1200-\\u1248\\u124A-\\u124D\\u1250-\\u1256\\u1258\\u125A-\\u125D\\u1260-\\u1288\\u128A-\\u128D\\u1290-\\u12B0\\u12B2-\\u12B5\\u12B8-\\u12BE\\u12C0\\u12C2-\\u12C5\\u12C8-\\u12D6\\u12D8-\\u1310\\u1312-\\u1315\\u1318-\\u135A\\u1380-\\u138F\\u13A0-\\u13F4\\u1401-\\u166C\\u166F-\\u1676\\u1681-\\u169A\\u16A0-\\u16EA\\u1700-\\u170C\\u170E-\\u1711\\u1720-\\u1731\\u1740-\\u1751\\u1760-\\u176C\\u176E-\\u1770\\u1780-\\u17B3\\u17D7\\u17DC\\u1820-\\u1877\\u1880-\\u18A8\\u18AA\\u1900-\\u191C\\u1950-\\u196D\\u1970-\\u1974\\u1980-\\u19A9\\u19C1-\\u19C7\\u1A00-\\u1A16\\u1B05-\\u1B33\\u1B45-\\u1B4B\\u1B83-\\u1BA0\\u1BAE\\u1BAF\\u1C00-\\u1C23\\u1C4D-\\u1C4F\\u1C5A-\\u1C7D\\u1D00-\\u1DBF\\u1E00-\\u1F15\\u1F18-\\u1F1D\\u1F20-\\u1F45\\u1F48-\\u1F4D\\u1F50-\\u1F57\\u1F59\\u1F5B\\u1F5D\\u1F5F-\\u1F7D\\u1F80-\\u1FB4\\u1FB6-\\u1FBC\\u1FBE\\u1FC2-\\u1FC4\\u1FC6-\\u1FCC\\u1FD0-\\u1FD3\\u1FD6-\\u1FDB\\u1FE0-\\u1FEC\\u1FF2-\\u1FF4\\u1FF6-\\u1FFC\\u2071\\u207F\\u2090-\\u2094\\u2102\\u2107\\u210A-\\u2113\\u2115\\u2119-\\u211D\\u2124\\u2126\\u2128\\u212A-\\u212D\\u212F-\\u2139\\u213C-\\u213F\\u2145-\\u2149\\u214E\\u2183\\u2184\\u2C00-\\u2C2E\\u2C30-\\u2C5E\\u2C60-\\u2C6F\\u2C71-\\u2C7D\\u2C80-\\u2CE4\\u2D00-\\u2D25\\u2D30-\\u2D65\\u2D6F\\u2D80-\\u2D96\\u2DA0-\\u2DA6\\u2DA8-\\u2DAE\\u2DB0-\\u2DB6\\u2DB8-\\u2DBE\\u2DC0-\\u2DC6\\u2DC8-\\u2DCE\\u2DD0-\\u2DD6\\u2DD8-\\u2DDE\\u2E2F\\u3005\\u3006\\u3031-\\u3035\\u303B\\u303C\\u3041-\\u3096\\u309D-\\u309F\\u30A1-\\u30FA\\u30FC-\\u30FF\\u3105-\\u312D\\u3131-\\u318E\\u31A0-\\u31B7\\u31F0-\\u31FF\\u3400\\u4DB5\\u4E00\\u9FC3\\uA000-\\uA48C\\uA500-\\uA60C\\uA610-\\uA61F\\uA62A\\uA62B\\uA640-\\uA65F\\uA662-\\uA66E\\uA67F-\\uA697\\uA717-\\uA71F\\uA722-\\uA788\\uA78B\\uA78C\\uA7FB-\\uA801\\uA803-\\uA805\\uA807-\\uA80A\\uA80C-\\uA822\\uA840-\\uA873\\uA882-\\uA8B3\\uA90A-\\uA925\\uA930-\\uA946\\uAA00-\\uAA28\\uAA40-\\uAA42\\uAA44-\\uAA4B\\uAC00\\uD7A3\\uF900-\\uFA2D\\uFA30-\\uFA6A\\uFA70-\\uFAD9\\uFB00-\\uFB06\\uFB13-\\uFB17\\uFB1D\\uFB1F-\\uFB28\\uFB2A-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBB1\\uFBD3-\\uFD3D\\uFD50-\\uFD8F\\uFD92-\\uFDC7\\uFDF0-\\uFDFB\\uFE70-\\uFE74\\uFE76-\\uFEFC\\uFF21-\\uFF3A\\uFF41-\\uFF5A\\uFF66-\\uFFBE\\uFFC2-\\uFFC7\\uFFCA-\\uFFCF\\uFFD2-\\uFFD7\\uFFDA-\\uFFDC]"),
    non_spacing_mark: RegExp("[\\u0300-\\u036F\\u0483-\\u0487\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u064B-\\u065E\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0900-\\u0902\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0955\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0CBC\\u0CBF\\u0CC6\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EB9\\u0EBB\\u0EBC\\u0EC8-\\u0ECD\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F90-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135F\\u1712-\\u1714\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1DC0-\\u1DE6\\u1DFD-\\u1DFF\\u20D0-\\u20DC\\u20E1\\u20E5-\\u20F0\\u2CEF-\\u2CF1\\u2DE0-\\u2DFF\\u302A-\\u302F\\u3099\\u309A\\uA66F\\uA67C\\uA67D\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA8C4\\uA8E0-\\uA8F1\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE26]"),
    space_combining_mark: RegExp("[\\u0903\\u093E-\\u0940\\u0949-\\u094C\\u094E\\u0982\\u0983\\u09BE-\\u09C0\\u09C7\\u09C8\\u09CB\\u09CC\\u09D7\\u0A03\\u0A3E-\\u0A40\\u0A83\\u0ABE-\\u0AC0\\u0AC9\\u0ACB\\u0ACC\\u0B02\\u0B03\\u0B3E\\u0B40\\u0B47\\u0B48\\u0B4B\\u0B4C\\u0B57\\u0BBE\\u0BBF\\u0BC1\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCC\\u0BD7\\u0C01-\\u0C03\\u0C41-\\u0C44\\u0C82\\u0C83\\u0CBE\\u0CC0-\\u0CC4\\u0CC7\\u0CC8\\u0CCA\\u0CCB\\u0CD5\\u0CD6\\u0D02\\u0D03\\u0D3E-\\u0D40\\u0D46-\\u0D48\\u0D4A-\\u0D4C\\u0D57\\u0D82\\u0D83\\u0DCF-\\u0DD1\\u0DD8-\\u0DDF\\u0DF2\\u0DF3\\u0F3E\\u0F3F\\u0F7F\\u102B\\u102C\\u1031\\u1038\\u103B\\u103C\\u1056\\u1057\\u1062-\\u1064\\u1067-\\u106D\\u1083\\u1084\\u1087-\\u108C\\u108F\\u109A-\\u109C\\u17B6\\u17BE-\\u17C5\\u17C7\\u17C8\\u1923-\\u1926\\u1929-\\u192B\\u1930\\u1931\\u1933-\\u1938\\u19B0-\\u19C0\\u19C8\\u19C9\\u1A19-\\u1A1B\\u1A55\\u1A57\\u1A61\\u1A63\\u1A64\\u1A6D-\\u1A72\\u1B04\\u1B35\\u1B3B\\u1B3D-\\u1B41\\u1B43\\u1B44\\u1B82\\u1BA1\\u1BA6\\u1BA7\\u1BAA\\u1C24-\\u1C2B\\u1C34\\u1C35\\u1CE1\\u1CF2\\uA823\\uA824\\uA827\\uA880\\uA881\\uA8B4-\\uA8C3\\uA952\\uA953\\uA983\\uA9B4\\uA9B5\\uA9BA\\uA9BB\\uA9BD-\\uA9C0\\uAA2F\\uAA30\\uAA33\\uAA34\\uAA4D\\uAA7B\\uABE3\\uABE4\\uABE6\\uABE7\\uABE9\\uABEA\\uABEC]"),
    connector_punctuation: RegExp("[\\u005F\\u203F\\u2040\\u2054\\uFE33\\uFE34\\uFE4D-\\uFE4F\\uFF3F]")
}


# detect common python stdlib methods - these will be auto-injected into the code when called
BASELIB = {}
STDLIB = [
    "abs",
    "bin",
    "cmp",
    "chr",
    "dir",
    "hex",
    "max",
    "min",
    "mixin",
    "print",
    "range",
    "reduce",
    "getattr",
    "setattr",
    "hasattr",

    # unique to RapydScript
    "eq",
    "bind",
    "rebind_all",

    # list operations
    "all",
    "any",
    "enumerate",
    "filter",
    "len",
    "map",
    "reversed",
    "sum",
    "zip",

    # errors
    "AssertionError",
    "IndexError",
    "KeyError",
    "TypeError",
    "ValueError",
]

IDENTIFIER_PAT = /^[a-z_$][_a-z0-9$]*$/i

class ImportError(Error):
    def __init__(self, message):
        self.message = message

def is_letter(code):
    return code >= 97 and code <= 122 or code >= 65 and code <= 90 or code >= 170 and UNICODE.letter.test(String.fromCharCode(code))

def is_digit(code):
    return code >= 48 and code <= 57

def is_alphanumeric_char(code):
    return is_digit(code) or is_letter(code)

def is_unicode_combining_mark(ch):
    return UNICODE.non_spacing_mark.test(ch) or UNICODE.space_combining_mark.test(ch)

def is_unicode_connector_punctuation(ch):
    return UNICODE.connector_punctuation.test(ch)

def is_identifier(name):
    return not RESERVED_WORDS(name) and IDENTIFIER_PAT.test(name)

def is_identifier_start(code):
    return code == 36 or code == 95 or is_letter(code)

def is_identifier_char(ch):
    code = ch.charCodeAt(0)
    return is_identifier_start(code) or is_digit(code) or code == 8204 or code == 8205 or is_unicode_combining_mark(ch) or is_unicode_connector_punctuation(ch)

def parse_js_number(num):
    if RE_HEX_NUMBER.test(num):
        return parseInt(num.substr(2), 16)
    elif RE_OCT_NUMBER.test(num):
        return parseInt(num.substr(1), 8)
    elif RE_DEC_NUMBER.test(num):
        return parseFloat(num)

def JS_Parse_Error(message, line, col, pos, is_eof):
    this.message = message
    this.line = line
    this.col = col
    this.pos = pos
    this.stack = Error().stack
    this.is_eof = is_eof

JS_Parse_Error.prototype.toString = def():
    return this.message + " (line: " + this.line + ", col: " + this.col + ", pos: " + this.pos + ")" + "\n\n" + this.stack

def js_error(message, filename, line, col, pos, is_eof):
    AST_Node.warn("ERROR: {message} [{file}:{line},{col}]", {
        message: message,
        file: filename,
        line: line,
        col: col
    })
    raise new JS_Parse_Error(message, line, col, pos, is_eof)

def is_token(token, type, val):
    return token.type == type and (val == None or val == undefined or token.value == val)

EX_EOF = {}

def tokenizer($TEXT, filename):  # {{{
    S = {
        text: $TEXT.replace(/\r\n?|[\n\u2028\u2029]/g, "\n").replace(/\uFEFF/g, ""),
        filename: filename,
        pos: 0,
        tokpos: 0,
        line: 1,
        tokline: 0,
        col: 0,
        tokcol: 0,
        newline_before: False,
        regex_allowed: False,
        comments_before: [],
        whitespace_before: [],
        newblock: False,
        endblock: False,
        indentation_matters: [ True ],
        cached_whitespace: "",
        prev: undefined,
        index_or_slice: [ False ]
    }
    def peek():
        return S.text.charAt(S.pos)

    def prevChar():
        return S.text.charAt(S.tokpos - 1)

    def next(signal_eof, in_string):
        ch = S.text.charAt(S.pos)
        S.pos += 1
        if signal_eof and not ch:
            raise EX_EOF

        if ch == "\n":
            S.newline_before = S.newline_before or not in_string
            S.line += 1
            S.col = 0
        else:
            S.col += 1
        return ch

    def find(what, signal_eof):
        pos = S.text.indexOf(what, S.pos)
        if signal_eof and pos == -1:
            raise EX_EOF
        return pos

    def start_token():
        S.tokline = S.line
        S.tokcol = S.col
        S.tokpos = S.pos

    def token(type, value, is_comment, keep_newline):

        S.regex_allowed = type == "operator" and not UNARY_POSTFIX[value] \
            or type == "keyword" and KEYWORDS_BEFORE_EXPRESSION(value) \
            or type == "punc" and PUNC_BEFORE_EXPRESSION(value)

        if type == "operator" and value == "is" and S.text.substr(S.pos).trimLeft().substr(0, 4).trimRight() == "not":
            next_token()
            value = "!=="

        if type == "operator" and OP_MAP[value]:
            value = OP_MAP[value]

        ret = {
            type: type,
            value: value,
            line: S.tokline,
            col: S.tokcol,
            pos: S.tokpos,
            endpos: S.pos,
            nlb: S.newline_before,
            file: filename
        }
        if not is_comment:
            ret.comments_before = S.comments_before
            S.comments_before = []
            # make note of any newlines in the comments that came before
            for i in range(len(ret.comments_before)):
                ret.nlb = ret.nlb or ret.comments_before[i].nlb

        if not keep_newline:
            S.newline_before = False

        if type == "punc":
            #            if (value == ":" && peek() == "\n") {
            if value == ":" and not S.index_or_slice[-1]
            and (not S.text.substring(S.pos + 1, find("\n")).trim() or not S.text.substring(S.pos + 1, find("#")).trim()):
                S.newblock = True
                S.indentation_matters.push(True)

            if value == "[":
                if S.prev and S.prev.type == "name":
                    S.index_or_slice.push(True)
                else:
                    S.index_or_slice.push(False)
                S.indentation_matters.push(False)
            elif value == "{" or value == "(":
                S.indentation_matters.push(False)
            elif value == "]":
                S.index_or_slice.pop()
                S.indentation_matters.pop()
            elif value == "}" or value == ")":
                S.indentation_matters.pop()
        S.prev = new AST_Token(ret)
        return S.prev

    # this will transform leading whitespace to block tokens unless
    # part of array/hash, and skip non-leading whitespace
    def parse_whitespace():
        leading_whitespace = ""
        whitespace_exists = False
        while WHITESPACE_CHARS(peek()):
            whitespace_exists = True
            ch = next()
            if ch == "\n":
                leading_whitespace = ""
            else:
                leading_whitespace += ch
        if peek() != "#":
            if not whitespace_exists:
                leading_whitespace = S.cached_whitespace
            else:
                S.cached_whitespace = leading_whitespace
            if S.newline_before or S.endblock:
                return test_indent_token(leading_whitespace)

    def test_indent_token(leading_whitespace):
        most_recent = S.whitespace_before[S.whitespace_before.length - 1] or ""
        S.endblock = False
        if S.indentation_matters[-1] and leading_whitespace != most_recent:
            if S.newblock and leading_whitespace and leading_whitespace.indexOf(most_recent) == 0:
                # positive indent, new block
                S.newblock = False
                S.whitespace_before.push(leading_whitespace)
                return 1
            elif most_recent and most_recent.indexOf(leading_whitespace) == 0:
                # negative indent, block is ending
                S.endblock = True
                S.whitespace_before.pop()
                return -1
            else:
                # indent mismatch, inconsistent indentation
                parse_error("Inconsistent indentation")
        else:
            return 0

    def read_while(pred):
        ret = ""
        i = 0
        while (ch = peek()) and pred(ch, i):
            i += 1
            ret += next()
        return ret

    def parse_error(err, is_eof):
        js_error(err, filename, S.tokline, S.tokcol, S.tokpos, is_eof)

    def read_num(prefix):
        has_e = False
        after_e = False
        has_x = False
        has_dot = prefix == "."
        num = read_while(def(ch, i):
            nonlocal after_e
            code = ch.charCodeAt(0)
            tmp_ = code
            if tmp_ == 120 or tmp_ == 88:
                # xX
                return has_x ? False : has_x = True
            elif tmp_ == 101 or tmp_ == 69:
                # eE
                return has_x ? True : (has_e ? False : has_e = after_e = True)
            elif tmp_ == 45:
                # -
                return after_e or i == 0 and not prefix
            elif tmp_ == 43:
                # +
                return after_e
            elif tmp_ == 46:
                # .
                after_e = False
                return not has_dot and not has_x and not has_e ? has_dot = True : False
            return is_alphanumeric_char(code)
        )
        if prefix:
            num = prefix + num

        valid = parse_js_number(num)
        if not isNaN(valid):
            return token("num", valid)
        else:
            parse_error("Invalid syntax: " + num)


    def read_escaped_char(in_string, digester):
        digester = digester or def(in_str):
            return next(True, in_str)

        ch = digester(in_string)
        tmp_ = ch.charCodeAt(0)
        if tmp_ == 110:
            return "\n"
        elif tmp_ == 114:
            return "\r"
        elif tmp_ == 116:
            return "	"
        elif tmp_ == 98:
            return "\b"
        elif tmp_ == 118:
            return "\u000b" # \v
        elif tmp_ == 102:
            return "\f"
        elif tmp_ == 48:
            return "\0"
        elif tmp_ == 120:
            return String.fromCharCode(hex_bytes(2, digester))  # \x
        elif tmp_ == 117:
            return String.fromCharCode(hex_bytes(4, digester))  # \u
        elif tmp_ == 10:
            return ""   # newline
        else:
            return ch

    def hex_bytes(n, digester):
        num = 0
        for i in range(n):
            digit = parseInt(digester(), 16)
            if isNaN(digit):
                parse_error("Invalid hex-character pattern in string")
            num = num << 4 | digit
        return num

    read_string = with_eof_error("Unterminated string constant", def():
        quote = next()
        ret = ""
        if peek() == quote:
            # two quotes in a row
            next(True)
            if peek() == quote:
                # multiline string (3 quotes in a row)
                next(True)
                i = find(quote + quote + quote, True) # location of string terminator
                if i != -1:
                    tmp = S.text.substring(S.pos, i)
                    S.pos = i + 3
                    while tmp.length:
                        # parse escaped characters
                        if tmp[0] == "\\":
                            tmp = tmp.substr(1)
                            ret += read_escaped_char(True, def():
                                nonlocal tmp
                                ch = tmp[0]
                                tmp = tmp.substr(1)
                                return ch
                            )
                        else:
                            ret += tmp[0]
                            tmp = tmp.substr(1)

                    # add traversed lines to the counter
                    find_newlines = ret.match(/\n/g)
                    if find_newlines:
                        S.line += find_newlines.length
                    return token("string", ret)
            else:
                return token("string", "")

        while True:
            ch = next(True)
            if ch == "\n":
                parse_error("End of line while scanning string literal.")

            if ch == "\\":
                # read OctalEscapeSequence (XXX: deprecated if "strict mode")
                # https://github.com/mishoo/RapydScript/issues/178
                octal_len = 0
                first = None
                ch = read_while(def(ch):
                    nonlocal first
                    if ch >= "0" and ch <= "7":
                        if not first:
                            first = ch
                            return octal_len += 1
                        elif first <= "3" and octal_len <= 2:
                            return octal_len += 1
                        elif first >= "4" and octal_len <= 1:
                            return octal_len += 1
                    return False
                )
                if octal_len > 0:
                    ch = String.fromCharCode(parseInt(ch, 8))
                elif peek() == "\n":
                    # skip newlines if escaped by backslash
                    next(True)
                    continue
                else:
                    ch = read_escaped_char(True)
            elif ch == quote:
                break
            ret += ch
        return token("string", ret)
    )

    def read_line_comment(shebang=False):
        if not shebang:
            next()
        i = find("\n")

        if i == -1:
            ret = S.text.substr(S.pos)
            S.pos = S.text.length
        else:
            ret = S.text.substring(S.pos, i)
            S.pos = i

        return token(shebang ? "shebang" : "comment1", ret, True)

    read_multiline_comment = with_eof_error("Unterminated multiline comment", def():
        next()
        i = find("*/", True)
        text = S.text.substring(S.pos, i)
        a = text.split("\n")
        n = a.length
        # update stream position
        S.pos = i + 2
        S.line += n - 1
        if n > 1:
            S.col = a[n - 1].length
        else:
            S.col += a[n - 1].length
        S.col += 2
        S.newline_before = S.newline_before or text.indexOf("\n") >= 0
        return token("comment2", text, True)
    )

    def read_name():
        backslash = False
        name = ""
        escaped = False

        while (ch = peek()) != None:
            if not backslash:
                if ch == "\\":
                    if S.text.charAt(S.pos + 1) == "\n":
                        # stitching lines together
                        S.pos += 2
                        continue
                    else:
                        # actual backslash
                        escaped = backslash = True
                        next()
                elif is_identifier_char(ch):
                    name += next()
                else:
                    break
            else:
                if ch != "u":
                    parse_error("Expecting UnicodeEscapeSequence -- uXXXX")
                ch = read_escaped_char()
                if not is_identifier_char(ch):
                    parse_error("Unicode char: " + ch.charCodeAt(0) + " is not valid in identifier")
                name += ch
                backslash = False

        if KEYWORDS(name) and escaped:
            hex = name.charCodeAt(0).toString(16).toUpperCase()
            name = "\\u" + "0000".substr(hex.length) + hex + name.slice(1)
        return name

    read_regexp = with_eof_error("Unterminated regular expression", def(regexp):
        prev_backslash = False

        in_class = False
        verbose_regexp = False
        in_comment = False

        if peek() == '/':
            next(True)
            if peek() == '/':
                verbose_regexp = True
                next(True)
            else: # empty regexp (//)
                mods = read_name()
                return token("regexp", RegExp(regexp, mods))

        while ch = next(True):
            if in_comment:
                if ch == '\n':
                    in_comment = False
                continue

            if prev_backslash:
                regexp += "\\" + ch
                prev_backslash = False
            elif ch == "[":
                in_class = True
                regexp += ch
            elif ch == "]" and in_class:
                in_class = False
                regexp += ch
            elif ch == "/" and not in_class:
                if verbose_regexp:
                    if peek() != '/':
                        regexp += '\\/'
                        continue
                    next(True)
                    if peek() != '/':
                        regexp += '\\/\\/'
                        continue
                    next(True)
                break
            elif ch == "\\":
                prev_backslash = True
            elif verbose_regexp and not in_class and ' \n\r\t'.indexOf(ch) != -1:
                pass
            elif verbose_regexp and not in_class and ch == '#':
                in_comment = True
            else:
                regexp += ch

        mods = read_name()
        return token("regexp", RegExp(regexp, mods))
    )

    def read_operator(prefix):
        def grow(op):
            if not peek():
                return op

            bigger = op + peek()
            if OPERATORS(bigger):
                next()
                return grow(bigger)
            else:
                return op
        op = grow(prefix or next())
        if op in ["++", "--", "===", "!=="]:
            parse_error("Invalid operator «" + op + "»")
        return token("operator", op)

    def handle_slash():
        next()
        return (S.regex_allowed ? read_regexp("") : read_operator("/"))

    def handle_dot():
        next()
        return (is_digit(peek().charCodeAt(0)) ? read_num(".") : token("punc", "."))

    def read_word():
        word = read_name()
        return (KEYWORDS_ATOM(word) ? token("atom", word) : (not KEYWORDS(word) ? token("name", word) : (OPERATORS(word) and prevChar() != "." ? token("operator", word) : token("keyword", word))))

    def with_eof_error(eof_error, cont):
        return def(x):
            try:
                return cont(x)
            except as ex:
                if ex is EX_EOF:
                    parse_error(eof_error, true)
                else:
                    raise

    def next_token(force_regexp):
        if force_regexp not in (None, undefined):
            return read_regexp(force_regexp)

        indent = parse_whitespace()
        #        if (indent == 1)
        #            return token("punc", "{");
        if indent == -1:
            return token("punc", "}", False, True)

        start_token()
        ch = peek()
        if not ch:
            return token("eof")

        code = ch.charCodeAt(0)
        tmp_ = code
        if tmp_ == 34 or tmp_ == 39:    # double-quote (") or single quote (')
            return read_string()
        elif tmp_ == 35:                # pound-sign (#)
            if S.pos == 0 and S.text.charAt(1) == '!':
                #shebang
                return read_line_comment(True)
            regex_allowed = S.regex_allowed
            S.comments_before.push(read_line_comment())
            S.regex_allowed = regex_allowed
            return next_token()
        elif tmp_ == 46:                # dot (.)
            return handle_dot()
        elif tmp_ == 47:                # slash (/)
            return handle_slash()

        if is_digit(code):
            return read_num()

        if PUNC_CHARS(ch):
            return token("punc", next())

        if OPERATOR_CHARS(ch):
            return read_operator()

        if code == 92 and S.text.charAt(S.pos + 1) == "\n":
            # backslash will consume the newline character that follows
            next()
            # backslash
            next()
            # newline
            S.newline_before = False
            return next_token()

        if code == 92 or is_identifier_start(code):
            return read_word()

        parse_error("Unexpected character «" + ch + "»")

    next_token.context = def(nc):
        nonlocal S
        if nc:
            S = nc
        return S

    return next_token
# }}}

# -----[ Parser (constants) ]-----
UNARY_PREFIX = makePredicate([
    "typeof",
    "void",
    "delete",
    "--",
    "++",
    "!",
    "~",
    "-",
    "+",
    "@"
])

UNARY_POSTFIX = makePredicate([ "--", "++" ])

ASSIGNMENT = makePredicate([ "=", "+=", "-=", "/=", "//=", "*=", "%=", ">>=", "<<=", ">>>=", "|=", "^=", "&=" ])

PRECEDENCE = def(a, ret):
    for i in range(a.length):
        b = a[i]
        for j in range(b.length):
            ret[b[j]] = i+1
    return ret
.call(this, [
    # lowest precedence
    [ "||" ],
    [ "&&" ],
    [ "|" ],
    [ "^" ],
    [ "&" ],
    [ "==", "===", "!=", "!==" ],
    [ "<", ">", "<=", ">=", "in", "instanceof" ],
    [ ">>", "<<", ">>>" ],
    [ "+", "-" ],
    [ "*", "/", "//", "%" ],
    [ "**" ]
    # highest precedence
], {})

STATEMENTS_WITH_LABELS = array_to_hash([ "for", "do", "while", "switch" ])

ATOMIC_START_TOKEN = array_to_hash([ "atom", "num", "string", "regexp", "name" ])

# -----[ Parser ]-----
def parse($TEXT, options):
    options = defaults(options, {
        strict: False,          # whether to use strict JavaScript mode
        filename: None,         # name of the file being parsed
        auto_bind: False,       # whether auto-binding of methods to classes is enabled
        module_id: '__main__',  # The id of the module being parsed
        es6: False,
        toplevel: None,
        classes: undefined      # Map of class names to AST_Class that are available in the global namespace (used by the REPL)
    })
    module_id = options.module_id
    IMPORTED = options.IMPORTED or {}
    IMPORTING = options.IMPORTING or {}
    IMPORTING[module_id] = True

    S = {
        input: (typeof $TEXT == "string" ? tokenizer($TEXT, options.filename) : $TEXT),
        token: None,
        prev: None,
        peeked: None,
        in_function: 0,
        in_directives: True,
        in_loop: 0,
        in_class: [ False ],
        classes: [ {} ],
        labels: [],
        decorators: [],
    }

    if options.classes:
        for cname in options.classes:
            obj = options.classes[cname]
            S.classes[0][cname] = { 'static':obj.static, 'bound':obj.bound }

    S.token = next()
    def is_(type, value):
        return is_token(S.token, type, value)

    def peek():
        return S.peeked or (S.peeked = S.input())

    def next():
        S.prev = S.token
        if S.peeked:
            S.token = S.peeked
            S.peeked = None
        else:
            S.token = S.input()

        S.in_directives = S.in_directives and (S.token.type == "string" or is_("punc", ";"))
        return S.token

    def prev():
        return S.prev

    def croak(msg, line, col, pos, is_eof):
        # note: undefined means nothing was passed in, None/null means a null value was passed in
        ctx = S.input.context()
        js_error(msg, ctx.filename, (line != undefined ? line : ctx.tokline),
                 (col != undefined ? col : ctx.tokcol), (pos != undefined ? pos : ctx.tokpos), is_eof)

    def token_error(token, msg):
        is_eof = (token.type == 'eof') ? true : false
        croak(msg, token.line, token.col, undefined, is_eof)

    def unexpected(token):
        if token == undefined:
            token = S.token
        token_error(token, "Unexpected token: " + token.type + " «" + token.value + "»")

    def expect_token(type, val):
        if is_(type, val):
            return next()
        token_error(S.token, "Unexpected token " + S.token.type + " «" + S.token.value + "»" +
                    ", expected " + type + " «" + val + "»")

    def expect(punc):
        return expect_token("punc", punc)

    def can_insert_semicolon():
        return not options.strict and (S.token.nlb or is_("eof") or is_("punc", "}"))

    def semicolon():
        if is_("punc", ";"):
            next()
            S.token.nlb = True

    def parenthesised():
        expect("(")
        exp = expression(True)
        expect(")")
        return exp

    def embed_tokens(parser):
        return def():
            start = S.token
            expr = parser()
            if expr == undefined:
                unexpected()
            end = prev()
            expr.start = start
            expr.end = end
            return expr

    def is_nested_comparison(stmt):
        """
        Check if the statement is a nested comparison
        """
        comparators = {
            "<": True,
            ">": True,
            "<=": True,
            ">=": True,
            "==": True,
            "!=": True,
            "===": True,
            "!==": True
        }
        if isinstance(stmt, AST_Binary) and stmt.operator in comparators \
                and isinstance(stmt.left, AST_Binary) and stmt.left.operator in comparators:
            return True
        else:
            return False

    def scan_for_top_level_callables(body):
        ans = []
        # Get the named functions and classes
        if Array.isArray(body):
            for name in dir(body):
                obj = body[name]
                if isinstance(obj, AST_Function) or isinstance(obj, AST_Class):
                    if obj.name:
                        ans.push(obj.name)
                    else:
                        token_error(obj.start, "Top-level functions must have names")
                else:
                    # skip inner scopes
                    if isinstance(obj, AST_Scope):
                        continue
                    for x in ['body', 'alternative']:
                        opt = obj[x]
                        if opt:
                            ans = ans.concat(scan_for_top_level_callables(opt))

                        if isinstance(opt, AST_Assign) and not (isinstance(opt.right, AST_Scope)):
                            ans = ans.concat(scan_for_top_level_callables(opt.right))
        elif body.body:
            # recursive descent into wrapper statements that contain body blocks
            ans = ans.concat(scan_for_top_level_callables(body.body))
            if body.alternative:
                ans = ans.concat(scan_for_top_level_callables(body.alternative))

        return ans

    def scan_for_classes(body):
        ans = {}
        for name in dir(body):
            obj = body[name]
            if isinstance(obj, AST_Class):
                ans[obj.name.name] = obj
        return ans

    def scan_for_local_vars(body):
        """
        Pick out all variables being assigned to from within this scope, we'll mark them as local

        body        body to be scanned
        """
        vars = []
        if Array.isArray(body):
            # this is a body of statements
            for stmt in dir(body):
                # skip inner scopes
                if isinstance(body[stmt], AST_Scope):
                    continue

                # recursive descent into conditional, loop and exception bodies
                [ "body", "alternative" ].forEach(def(option):
                    nonlocal vars
                    opt = body[stmt][option]
                    if opt:
                        vars = vars.concat(scan_for_local_vars(opt))

                    if isinstance(opt, AST_Assign) and not (isinstance(opt.right, AST_Scope)):
                        vars = vars.concat(scan_for_local_vars(opt.right))
                )

                # pick up iterators from loops
                if isinstance(body[stmt], AST_ForIn):
                    if isinstance(body[stmt].init, AST_Array):
                        # iteration via implicit tuple
                        vars.push("ՐՏ_Unpack")
                        body[stmt].init.elements.forEach(def(elem):
                            if vars.indexOf(elem.name) == -1:
                                vars.push(elem.name)
                        )
                    elif vars.indexOf(body[stmt].init.name) == -1:
                        # iteration via a single variable
                        vars.push(body[stmt].init.name)
                elif isinstance(body[stmt], AST_DWLoop):
                    vars = vars.concat(scan_for_local_vars(body[stmt]))
                elif isinstance(body[stmt], AST_If) \
                        and is_nested_comparison(body[stmt].condition):
                    # if statement condition with complex comparison
                    vars.push("ՐՏ_Temp")
                elif isinstance(body[stmt], AST_Exit) and is_nested_comparison(body[stmt].value):
                    # returning a nested conditional
                    vars.push("ՐՏ_Temp")

        elif body.body:
            # recursive descent into wrapper statements that contain body blocks
            vars = vars.concat(scan_for_local_vars(body.body))
            if body.alternative:
                vars = vars.concat(scan_for_local_vars(body.alternative))

        elif isinstance(body, AST_Assign):
            # this is a single assignment operator
            if isinstance(body.left, AST_Array):
                # assignment to an implicit tuple
                vars.push("ՐՏ_Unpack")
                body.left.elements.forEach(def(elem):
                    if not (isinstance(elem, AST_PropAccess)) and vars.indexOf(elem.name) == -1:
                        vars.push(elem.name)
                )
            elif body.left.name and vars.indexOf(body.left.name) == -1:
                # assignment to a single variable
                vars.push(body.left.name)

            if is_nested_comparison(body.right):
                # assignment of nested conditional result to a variable
                vars.push("ՐՏ_Temp")
            elif isinstance(body.right, AST_Conditional) and is_nested_comparison(body.right.condition):
                # assignment of a ternary condition result that uses nested conditional
                vars.push("ՐՏ_Temp")

        elif isinstance(body, AST_Conditional) and is_nested_comparison(body.condition):
            # ternary condition that uses nested conditional and triggers other logic
            # this is basically a really ugly way to write an if/else
            vars.push("ՐՏ_Temp")

        elif is_nested_comparison(body):
            # statement itself is a stand-alone nested conditional - programmatically this would probably
            # be a useless statement
            vars.push("ՐՏ_Temp")

        return vars

    def scan_for_nonlocal_defs(body):
        vars = []
        if Array.isArray(body):
            for stmt in dir(body):
                if isinstance(body[stmt], AST_Scope):
                    continue

                # don't invade nested scopes
                if isinstance(body[stmt], AST_Definitions):
                    body[stmt].definitions.forEach(def(vardef):
                        vars.push(vardef.name.name)
                    )

                [ "body", "alternative" ].forEach(def(option):
                    nonlocal vars
                    opt = body[stmt][option]
                    if opt:
                        vars = vars.concat(scan_for_nonlocal_defs(opt))

                )

        elif body.body:
            vars = vars.concat(scan_for_nonlocal_defs(body.body))
            if body.alternative:
                vars = vars.concat(scan_for_nonlocal_defs(body.alternative))


        return vars

    statement = embed_tokens(def():
        if is_("operator", "/") or is_("operator", "/="):
            S.peeked = None
            S.token = S.input(S.token.value.substr(1))

        tmp_ = S.token.type
        if tmp_ == "string":
            dir = S.in_directives
            stat = simple_statement()
            # XXXv2: decide how to fix directives
            if dir and isinstance(stat.body, AST_String) and not is_("punc", ","):
                return new AST_Directive({
                    value: stat.body.value
                })

            return stat
        elif tmp_ == "shebang":
            tmp_ = S.token.value
            next()
            return new AST_Directive({
                value: tmp_
            })
        elif tmp_ == "num" or tmp_ == "regexp" or tmp_ == "operator" or tmp_ == "atom":
            return simple_statement()
        elif tmp_ == "punc":
            tmp_ = S.token.value
            if tmp_ == ":":
                return new AST_BlockStatement({
                    start: S.token,
                    body: block_(),
                    end: prev()
                })
            elif tmp_ == "{" or tmp_ == "[" or tmp_ == "(":
                return simple_statement()
            elif tmp_ == ";":
                next()
                return new AST_EmptyStatement()
            else:
                unexpected()
        elif tmp_ == "name":
            return (is_token(peek(), "punc", ":") ? labeled_statement() : simple_statement())
        elif tmp_ == "keyword":
            tmp_ = S.token.value

            if ES6_KEYWORDS(tmp_) and not options.es6:
                token_error(prev(), "«" + tmp_ + "» keyword not supported with ES5-compatible output, use --ecmascript6 compilation flag")

            next()
            if tmp_ == "break":
                return break_cont(AST_Break)
            elif tmp_ == "continue":
                return break_cont(AST_Continue)
            elif tmp_ == "debugger":
                semicolon()
                return new AST_Debugger()
            elif tmp_ == "do":
                return new AST_Do({
                    body: in_loop(statement),
                    condition: def():
                        expect(".")
                        expect_token("keyword", "while")
                        tmp = expression(True)
                        semicolon()
                        return tmp
                    .call(this)
                })
            elif tmp_ == "while":
                return new AST_While({
                    condition: expression(True),
                    body: in_loop(statement)
                })
            elif tmp_ == "for":
                if is_("name", "JS"):
                    return for_js()
                return for_()
            elif tmp_ == "from":
                return import_(True)
            elif tmp_ == "import":
                return import_(False)
            elif tmp_ == "class":
                BASELIB["extends"] = True
                if options.auto_bind:
                    BASELIB["rebind_all"] = True
                    BASELIB["bind"] = True  # used by rebind_all
                return class_()
            elif tmp_ == "def":
                start = prev()
                func = function_(S.in_class[-1])
                func.start = start
                func.end = prev()
                chain = subscripts(func, True)
                if chain == func:
                    return func
                else:
                    return new AST_SimpleStatement({
                        start: start,
                        body: chain,
                        end: prev()
                    })
            elif tmp_ == "if":
                return if_()
            elif tmp_ == "pass":
                semicolon()
                return new AST_EmptyStatement()
            elif tmp_ == "return" or tmp_ == "yield":
                if S.in_function == 0:
                    croak("'return' outside of function")

                return new AST_Return({
                    value: (is_("punc", ";") ?
                        def():
                            semicolon()
                            return None
                        .call(this) : (can_insert_semicolon() ? None
                            : def():
                                tmp = expression(True)
                                semicolon()
                                return tmp
                            .call(this)
                        )
                    )
                })
            elif tmp_ == "switch":
                return new AST_Switch({
                    expression: parenthesised(),
                    body: in_loop(switch_body_)
                })
            elif tmp_ == "raise":
                if S.token.nlb:
                    return new AST_Throw({
                        value: new AST_SymbolCatch({
                            name: "ՐՏ_Exception"
                        })
                    })

                tmp = expression(True)
                semicolon()
                return new AST_Throw({
                    value: tmp
                })
            elif tmp_ == "try":
                return try_()
            elif tmp_ == "nonlocal":
                tmp = nonlocal_()
                semicolon()
                return tmp
            elif tmp_ == "const":
                tmp = const_()
                semicolon()
                return tmp
            elif tmp_ == "with":
                return new AST_With({
                    expression: parenthesised(),
                    body: statement()
                })
            else:
                unexpected()
    )

    def labeled_statement():
        label = as_symbol(AST_Label)
        if find_if(def(l):
            return l.name == label.name
        , S.labels):
            # ECMA-262, 12.12: An ECMAScript program is considered
            # syntactically incorrect if it contains a
            # LabelledStatement that is enclosed by a
            # LabelledStatement with the same Identifier as label.
            croak("Label " + label.name + " defined twice")

        expect(":")
        S.labels.push(label)
        stat = statement()
        S.labels.pop()
        return new AST_LabeledStatement({
            body: stat,
            label: label
        })

    def simple_statement(tmp):
        tmp = expression(True)
        semicolon()
        return new AST_SimpleStatement({
            body: tmp
        })

    def break_cont(type):
        label = None
        if not can_insert_semicolon():
            label = as_symbol(AST_LabelRef, True)

        if label != None:
            if not find_if(def(l):
                return l.name == label.name
            , S.labels):
                croak("Undefined label " + label.name)

        elif S.in_loop == 0:
            croak(type.TYPE + " not inside a loop or switch")

        semicolon()
        return new type({
            label: label
        })

    def seq_to_array(seq):
        # convert AST_Seq into AST_Array
        tmp = []
        iter = seq
        while iter and iter.car:
            tmp.push(iter.car)
            iter = iter.cdr
        tmp.push(iter)

        return new AST_Array({
            start: seq.start,
            elements: tmp,
            end: seq.end
        })

    def for_(list_comp):
        #        expect("(");
        init = None
        if not is_("punc", ";"):
            init = expression(True, True)
            # standardize AST_Seq into array now for consistency
            if isinstance(init, AST_Seq):
                init = seq_to_array(init)

            if is_("operator", "in"):
                if isinstance(init, AST_Var) and init.definitions.length > 1:
                    croak("Only one variable declaration allowed in for..in loop")
                next()
                return for_in(init, list_comp)

        unexpected()

    def for_in(init, list_comp):
        lhs = (isinstance(init, AST_Var) ? init.definitions[0].name : None)
        obj = expression(True)
        BASELIB["iterable"] = True
        #        expect(")");
        if list_comp:
            return {
                init: init,
                name: lhs,
                object: obj
            }

        return new AST_ForIn({
            init: init,
            name: lhs,
            object: obj,
            body: in_loop(statement)
        })

    # A native JavaScript for loop - for JS("var i=0; i<5000; i++"):
    def for_js():
        condition = expression(True, True)
        return new AST_ForJS({
            condition: condition,
            body: in_loop(statement)
        })

    # scan function/class body for nested class declarations
    def get_class_in_scope(expr):
        # TODO: Currently if a local variable shadows a class name defined in
        # an outerscope, the logic below will identify that variable as a
        # class. This bug was always present. Fixing it will require the parser
        # to maintain a list of local variables for every AST_Scope and provide
        # an easy way to walk the ast tree upwards.
        if isinstance(expr, AST_SymbolRef):
            # check Native JS classes
            if NATIVE_CLASSES.hasOwnProperty(expr.name):
                return NATIVE_CLASSES[expr.name]

            # traverse in reverse to check local variables first
            for s in range(S.classes.length-1, -1, -1):
                if S.classes[s].hasOwnProperty(expr.name):
                    return S.classes[s][expr.name]

        elif isinstance(expr, AST_Dot):
            referenced_path = []
            # this one is for detecting classes inside modules and eventually nested classes
            while isinstance(expr, AST_Dot):
                referenced_path.unshift(expr.property)
                expr = expr.expression
            if isinstance(expr, AST_SymbolRef):
                referenced_path.unshift(expr.name)
                # now 'referenced_path' should contain the full path of potential class
                if len(referenced_path) > 1:
                    class_name = referenced_path.join('.')
                    for s in range(S.classes.length-1, -1, -1):
                        if S.classes[s].hasOwnProperty(class_name):
                            return S.classes[s][class_name]
        return False

    def do_import(key):
        if IMPORTED.hasOwnProperty(key):
            return
        if IMPORTING.hasOwnProperty(key) and IMPORTING[key]:
            raise ImportError('Detected a recursive import of: ' + key + ' while importing: ' + module_id)

        # Ensure that the package containing this module is also imported
        package_module_id = key.split('.')[:-1].join('.')
        if len(package_module_id) > 0:
            do_import(package_module_id)

        def safe_read(base_path):
            for i, path in enumerate([base_path + '.pyj', base_path + '/__init__.pyj']):
                try:
                    return [options.readfile(path, "utf-8"), path]
                except as e:
                    if e.code == 'ENOENT' or e.code == 'EPERM' or e.code == 'EACCESS':
                        if i == 1:
                            return None, None
                    if i == 1:
                        raise

        src_code = filename = None
        modpath = key.replace('.', '/')

        for location in [options.basedir, options.libdir]:
            if location:
                data, filename = safe_read(location + '/' + modpath)
                if data is not None:
                    src_code = data
                    break
        if src_code is None:
            raise "Failed Import: '" + key + "' module doesn't exist in either '" + options.basedir + "' or '" + options.libdir + "'"
        contents = parse(src_code, {
                filename: filename,
                toplevel: None,
                readfile: options.readfile,
                basedir: options.basedir,
                libdir: options.libdir,
                module_id: key,
                IMPORTED: IMPORTED,
                IMPORTING: IMPORTING,
        })
        if len(package_module_id) > 0:
            IMPORTED[package_module_id].submodules.push(key)


    import_ = def(from_import):
        ans = new AST_Imports({'imports':[]})
        while True:
            tmp = name = expression(False)
            key = ''
            while isinstance(tmp, AST_Dot):
                key = "." + tmp.property + key
                tmp = tmp.expression
            key = tmp.name + key
            alias = None
            if not from_import and is_('keyword', 'as'):
                next()
                alias = as_symbol(AST_SymbolAlias)
            imp = new AST_Import({
                'module': name,
                'key': key,
                'alias': alias,
                'argnames':None,
                'body':def():
                    return IMPORTED[key]
            })
            ans.imports.push(imp)
            if from_import:
                break
            if is_('punc', ','):
                next()
            else:
                break

        for imp in ans['imports']:
            do_import(imp.key)
            classes = IMPORTED[key].classes
            if from_import:
                expect_token("keyword", "import")
                imp.argnames = argnames = []
                while True:
                    aname = as_symbol(AST_ImportedVar)
                    if is_('keyword', 'as'):
                        next()
                        aname.alias = as_symbol(AST_SymbolAlias)
                    argnames.push(aname)
                    if is_('punc', ','):
                        next()
                    else:
                        break

                # Put imported class names in the outermost scope
                for argvar in argnames:
                    obj = classes[argvar.name]
                    if obj:
                        key = (argvar.alias) ? argvar.alias.name : argvar.name
                        S.classes[-1][key] = { "static": obj.static, bound: obj.bound }
            else:
                for i in dir(classes):
                    obj = classes[i]
                    if isinstance(obj, AST_Class):
                        key = (imp.alias) ? imp.alias.name : imp.key
                        S.classes[-1][key + '.' + obj.name.name] = { 'static': obj.static, bound: obj.bound }

        return ans


    class_ = def():
        name = as_symbol(AST_SymbolDefun)
        if not name:
            unexpected()

        # detect external classes
        externaldecorator = S.decorators.indexOf("external")
        if externaldecorator != -1:
            S.decorators.splice(externaldecorator, 1)

        class_details = {
            "static": [],
            bound: {}
        }

        # class setup
        definition = new AST_Class({
            name: name,
            module_id:module_id,
            parent: (def():
                if is_("punc", "("):
                    next()
                    a = expr_atom(False)
                    expect(")")
                    return a
                else:
                    return None
            )(),
            localvars: [],
            "static": class_details.static,
            external: externaldecorator != -1,
            bound: class_details.bound,
            statements: [],
            decorators: (def():
                d = []
                S.decorators.forEach(def(decorator):
                    if decorator == 'kwargs':
                        BASELIB['kwargs'] = True
                    d.push(new AST_Decorator({
                        name: decorator
                    }))
                )
                S.decorators = []
                return d
            )(),
            body: (def(loop, labels):
                # navigate to correct location in the module tree and append the class

                # state "push"
                S.in_class.push(name.name)
                S.classes[S.classes.length - 1][name.name] = class_details
                S.classes.push({})
                S.in_function += 1
                S.in_directives = True
                S.in_loop = 0
                S.labels = []

                a = block_()

                # state "pop"
                S.in_function -= 1
                S.classes.pop()
                S.in_class.pop()
                S.in_loop = loop
                S.labels = labels

                return a
            )(S.in_loop, S.labels)
        })

        # find the constructor
        for i in dir(definition.body):
            stmt = definition.body[i]
            if isinstance(stmt, AST_Method) and stmt.name.name == "__init__":
                definition.init = stmt
                break

        # find class variables
        class_var_names = {}
        # Ensure that if a class variable refers to another class variable in
        # its initialization, the referenced variables' names are correctly
        # mangled.
        def walker():
            this._visit = def(node, descend):
                if isinstance(node, AST_Method):
                    class_var_names[node.name.name] = True
                    return
                elif isinstance(node, AST_Assign) and isinstance(node.left, AST_SymbolRef):
                    class_var_names[node.left.name] = True

                for child in node:
                    if isinstance(node[child], AST_SymbolRef) and Object.prototype.hasOwnProperty.call(class_var_names, node[child].name):
                        node[child] = new AST_SymbolClassRef({
                            'class': name,
                            'name': node[child].name
                        })
                if descend:
                    descend.call(node)
        visitor = new walker()

        for stmt in definition.body:
            if not isinstance(stmt, AST_Class) and not isinstance(stmt, AST_Method):
                stmt.walk(visitor)
                definition.statements.push(stmt)

        return definition

    function_ = def(in_class, ctor):
        is_accessor = ctor is AST_Accessor
        name = (is_("name") ? as_symbol((in_class ? AST_SymbolDefun : (is_accessor ? AST_SymbolAccessor : AST_SymbolLambda))) : (is_accessor and (is_("string") or is_("num")) ? as_atom_node() : None))
        if in_class and not name:
            unexpected()

        staticmethod = False
        if in_class:
            staticloc = S.decorators.indexOf("staticmethod")
            if staticloc != -1:
                S.decorators.splice(staticloc, 1)
                S.classes[S.classes.length - 2][in_class].static.push(name.name)
                staticmethod = True
            elif name.name != "__init__" and options.auto_bind:
                BASELIB["bind"] = True
                S.classes[S.classes.length - 2][in_class].bound[name.name] = True

        expect("(")
        if not ctor:
            ctor = in_class ? AST_Method : AST_Function

        definition = new ctor({
            name: name,
            argnames: (def(a):
                defaults = {}
                first = True
                seen_names = {}

                def get_arg():
                    if Object.prototype.hasOwnProperty.call(seen_names, S.token.value):
                        token_error(prev(), "Can't repeat parameter names")
                    if S.token.value == 'arguments':
                        token_error(prev(), "Can't use the name arguments as a parameter name, it is reserved by JavaScript")
                    seen_names[S.token.value] = True
                    return as_symbol(AST_SymbolFunarg)

                while not is_("punc", ")"):
                    if first:
                        first = False
                    else:
                        expect(",")
                    if is_('operator', '**'):

                        # FIXME: temporary assertion while I get the logic tested and out the door
                        token_error(prev(), "**kwargs in function definition is not implemented yet, work in progress")

                        # **kwargs
                        next()
                        if a.kwargs:
                            token_error(prev(), "Can't define multiple **kwargs in function definition")
                        a.kwargs = get_arg()
                    elif is_('operator', '*'):
                        # *args
                        next()
                        if a.starargs:
                            token_error(prev(), "Can't define multiple *args in function definition")
                        if a.kwargs:
                            token_error(prev(), "Can't define *args after **kwargs in function definition")
                        a.starargs = get_arg()
                    else:
                        if a.starargs or a.kwargs:
                            token_error(prev(), "Can't define a formal parameter after *args or **kwargs")
                        a.push(get_arg())
                        if is_("operator", "="):
                            if a.kwargs:
                                token_error(prev(), "Can't define an optional formal parameter after **kwargs")
                            val = prev().value
                            next()
                            defaults[val] = expression(False)
                            a.has_defaults = True
                        else:
                            if a.has_defaults:
                                token_error(prev(), "Can't define required formal parameters after optional formal parameters")

                next()
                a.defaults = defaults
                return a
            )([]),
            generator: False,
            localvars: [],
            decorators: (def():
                d = []
                S.decorators.forEach(def(decorator):
                    d.push(new AST_Decorator({
                        name: decorator
                    }))
                )
                S.decorators = []
                return d
            )(),
            body: (def(loop, labels):
                # parse function content

                # state "push"
                S.in_class.push(False)
                S.classes.push({})
                S.in_function += 1
                S.in_directives = True
                S.in_loop = 0
                S.labels = []

                a = block_()

                # state "pop"
                S.in_function -= 1
                S.classes.pop()
                S.in_class.pop()
                S.in_loop = loop
                S.labels = labels

                return a
            )(S.in_loop, S.labels)
        })
        if isinstance(definition, AST_Method):
            definition.static = staticmethod

        # detect local variables, strip function arguments
        assignments = scan_for_local_vars(definition.body, False).filter(def(element, index, arr):
            return arr.lastIndexOf(element) is index
        )
        for i in range(assignments.length):
            for j in range(definition.argnames.length+1):
                if j == definition.argnames.length:
                    definition.localvars.push(new_symbol(AST_SymbolVar, assignments[i]))
                elif j < definition.argnames.length and assignments[i] == definition.argnames[j].name:
                    break

        nonlocals = scan_for_nonlocal_defs(definition.body)
        nonlocals.forEach(def(variable):
            for i in dir(definition.localvars).reverse():
                if definition.localvars[i].name == variable:
                    definition.localvars.splice(i, 1)
        )
        return definition

    def if_():
        cond = expression(True)
        body = statement()
        belse = None
        if is_("keyword", "elif") or is_("keyword", "else"):
            if is_("keyword", "else"):
                next()
            else:
                S.token.value = "if"
            # effectively converts 'elif' to 'else if'
            belse = statement()

        return new AST_If({
            condition: cond,
            body: body,
            alternative: belse
        })

    def block_():
        expect(":")
        a = []
        if not S.token.nlb:
            while not S.token.nlb:
                if is_("eof"):
                    unexpected()
                a.push(statement())
        else:
            while not is_("punc", "}"):
                if is_("eof"):
                    # end of file, terminate block automatically
                    return a
                a.push(statement())
            next()
        return a

    def switch_body_():
        expect("{")
        a = []
        cur = None
        branch = None

        while not is_("punc", "}"):
            if is_("eof"):
                unexpected()

            if is_("keyword", "case"):
                if branch:
                    branch.end = prev()

                cur = []
                branch = new AST_Case({
                    start: (def():
                        tmp = S.token
                        next()
                        return tmp
                    )(),
                    expression: expression(True),
                    body: cur
                })
                a.push(branch)
                expect(":")
            elif is_("keyword", "default"):
                if branch:
                    branch.end = prev()

                cur = []
                branch = new AST_Default({
                    start: (def():
                        tmp = S.token
                        next()
                        expect(":")
                        return tmp
                    )(),
                    body: cur
                })
                a.push(branch)
            else:
                if not cur:
                    unexpected()
                cur.push(statement())

        if branch:
            branch.end = prev()
        next()
        return a

    def try_():
        body = block_()
        bcatch = []
        bfinally = None
        while is_("keyword", "except"):
            start = S.token
            next()
            exceptions = []
            if not is_("punc", ":") and not is_("keyword", "as"):
                exceptions.push(as_symbol(AST_SymbolVar))
                while is_("punc", ","):
                    next()
                    exceptions.push(as_symbol(AST_SymbolVar))

            name = None
            if is_("keyword", "as"):
                next()
                name = as_symbol(AST_SymbolCatch)

            bcatch.push(new AST_Except({
                start: start,
                argname: name,
                errors: exceptions,
                body: block_(),
                end: prev()
            }))

        if is_("keyword", "finally"):
            start = S.token
            next()
            bfinally = new AST_Finally({
                start: start,
                body: block_(),
                end: prev()
            })

        if not bcatch.length and not bfinally:
            croak("Missing except/finally blocks")

        return new AST_Try({
            body: body,
            bcatch: (bcatch.length ? new AST_Catch({
                body: bcatch
            }) : None),
            bfinally: bfinally
        })

    def vardefs(no_in, in_const):
        a = []
        while True:
            a.push(new AST_VarDef({
                start: S.token,
                name: as_symbol(in_const ? AST_SymbolConst : AST_SymbolVar),
                value: (is_("operator", "=") ? (next(), expression(False, no_in)) : None),
                end: prev()
            }))
            if not is_("punc", ","):
                break
            next()

        return a

    nonlocal_ = def(no_in):
        return new AST_Var({
            start: prev(),
            definitions: vardefs(no_in, False),
            end: prev()
        })

    const_ = def():
        return new AST_Const({
            start: prev(),
            definitions: vardefs(False, True),
            end: prev()
        })

    new_ = def():
        start = S.token
        expect_token("operator", "new")
        newexp = expr_atom(False)

        if is_("punc", "("):
            next()
            args = expr_list(")")
        else:
            args = []

        return subscripts(new AST_New({
            start: start,
            expression: newexp,
            args: args,
            end: prev()
        }), True)

    def as_atom_node(token):
        tok = token or S.token
        tmp_ = tok.type
        if tmp_ == "name":
            ret = as_symbol(AST_SymbolRef, token=tok)
        elif tmp_ == "num":
            ret = new AST_Number({
                start: tok,
                end: tok,
                value: tok.value
            })
        elif tmp_ == "string":
            ret = new AST_String({
                start: tok,
                end: tok,
                value: tok.value
            })
        elif tmp_ == "regexp":
            ret = new AST_RegExp({
                start: tok,
                end: tok,
                value: tok.value
            })
        elif tmp_ == "atom":
            tmp__ = tok.value
            if tmp__ == "False":
                ret = new AST_False({
                    start: tok,
                    end: tok
                })
            elif tmp__ == "True":
                ret = new AST_True({
                    start: tok,
                    end: tok
                })
            elif tmp__ == "None":
                ret = new AST_Null({
                    start: tok,
                    end: tok
                })

        if not token:
            next()
        return ret

    expr_atom = def(allow_calls):
        if is_("operator", "new"):
            return new_()

        start = S.token
        if is_("punc"):
            tmp_ = start.value
            if tmp_ == "(":
                next()
                ex = expression(True)
                ex.start = start
                ex.end = S.token
                if isinstance(ex, AST_SymbolRef):
                    ex.parens = True
                expect(")")
                return subscripts(ex, allow_calls)
            elif tmp_ == "[":
                return subscripts(array_(), allow_calls)
            elif tmp_ == "{":
                return subscripts(object_(), allow_calls)

            unexpected()

        if is_("keyword", "class"):
            next()
            cls = class_()
            cls.start = start
            cls.end = prev()
            return subscripts(cls, allow_calls)

        if is_("keyword", "def"):
            next()
            func = function_(False)
            func.start = start
            func.end = prev()
            return subscripts(func, allow_calls)

        if ATOMIC_START_TOKEN[S.token.type]:
            return subscripts(as_atom_node(), allow_calls)

        unexpected()

    def expr_list(closing, allow_trailing_comma, allow_empty, func_call):
        first = True
        a = []
        saw_starargs = False
        while not is_("punc", closing):
            if saw_starargs:
                token_error(prev(), "*args must be the last argument in a function call")

            if first:
                first = False
            else:
                expect(",")
            if allow_trailing_comma and is_("punc", closing):
                break

            if is_("operator", "*") and func_call:
                saw_starargs = True
                next()

            if is_("punc", ",") and allow_empty:
                a.push(new AST_Hole({
                    start: S.token,
                    end: S.token
                }))
            else:
                a.push(expression(False))

        if func_call:
            tmp = []
            tmp.kwargs = []
            for i, arg in enumerate(a):
                if isinstance(arg, AST_Assign):
                    # arg=val
                    BASELIB['kwargs'] = True
                    tmp.kwargs.push([arg.left, arg.right])
                else:
                    # regular argument
                    tmp.push(arg)
            a = tmp

        next()
        if saw_starargs:
            a.starargs = True
        return a

    def func_call_list():
        a = []
        first = True
        a.kwargs = []
        a.kwarg_items = kwargs = []
        a.starargs = False
        while not is_("punc", ')'):
            if first:
                first = False
            else:
                expect(",")
            if is_('operator', '*'):
                # starargs argument
                next()
                arg = expression(False)
                arg.is_array = True
                a.push(arg)
                a.starargs = True
            elif is_('operator', '**'):
                # kwargs argument
                BASELIB['kwargs'] = True
                next()
                kwargs.push(as_symbol(AST_SymbolVar, False))
            else:
                # arg=val assignment
                arg = expression(False)
                if isinstance(arg, AST_Assign):
                    BASELIB['kwargs'] = True
                    a.kwargs.push([arg.left, arg.right])
                else:
                    a.push(arg)
        next()
        return a

    def read_comprehension(object):
        # shared by list and dict comprehensions
        terminator = isinstance(object, AST_DictComprehension) ? '}' : ']'
        expect_token('keyword', 'for')
        forloop = for_(True)
        BASELIB["iterable"] = True
        object.init = forloop.init
        object.name = forloop.name
        object.object = forloop.object
        object.condition = is_("punc", terminator) ? None : (expect_token("keyword", "if"), expression(True))
        expect(terminator)
        return object

    array_ = embed_tokens(def():
        expect("[")
        expr = []
        if not is_("punc", "]"):
            expr.push(expression(False))
            if is_("keyword", "for"):
                # list comprehension
                return read_comprehension(new AST_ListComprehension({ statement: expr[0] }))

            if is_("operator", "til"):
                # up to but not including upper limit
                BASELIB['range'] = True
                next()
                expr.push(expression(False))
                ret = subscripts(new AST_Call({
                    start: S.token,
                    expression: new AST_SymbolRef({
                        name: "range"
                    }),
                    args: expr,
                    end: prev()
                }), True)
                expect("]")
                return ret
            elif is_("operator", "to"):
                # now add a tiny number to make sure we include the upper limit
                BASELIB['range'] = True
                next()
                expr.push(new AST_Binary({
                    left: expression(False),
                    operator: "+",
                    right: new AST_Number({
                        value: 0.000001
                    })
                }))
                ret = subscripts(new AST_Call({
                    start: S.token,
                    expression: new AST_SymbolRef({
                        name: "range"
                    }),
                    args: expr,
                    end: prev()
                }), True)
                expect("]")
                return ret
            elif not is_("punc", "]"):
                expect(",")

        return new AST_Array({
            elements: expr.concat(expr_list("]", not options.strict, True))
        })
    )
    object_ = embed_tokens(def():
        maybe_dict_comprehension = False
        expect("{")
        first = True
        a = []
        while not is_("punc", "}"):
            if not first:
                expect(",")
            if not options.strict and is_("punc", "}"):
                # allow trailing comma
                break

            start = S.token
            type = start.type
            if first and peek().value != ':':
                # possibly dict comprehension
                maybe_dict_comprehension = True
                key = expression(False)
                name = None
            else:
                key = as_property_name()
                name = key.value
                quoted = key.type == "string"

            if type == "name" and not is_("punc", ":"):
                if name == "get":
                    a.push(new AST_ObjectGetter({
                        start: start,
                        key: name,
                        quoted: quoted,
                        value: function_(False, AST_Accessor),
                        end: prev()
                    }))
                    continue

                if name == "set":
                    a.push(new AST_ObjectSetter({
                        start: start,
                        key: name,
                        quoted: quoted,
                        value: function_(False, AST_Accessor),
                        end: prev()
                    }))
                    continue

            if first and not is_('punc', ':'):
                # possibly a dict comprehension, continue parsing
                while not is_('punc', ':'):
                    aaa = expression(False)
                    console.log(aaa)
            expect(":")

            a.push(new AST_ObjectKeyVal({
                start: start,
                key: name,
                quoted: quoted,
                value: expression(False),
                end: prev()
            }))

            if a.length == 1 and is_('keyword', 'for'):
                return read_comprehension(new AST_DictComprehension({
                    statement: maybe_dict_comprehension ? key : as_atom_node(a[0].start),
                    value_statement: a[0].value
                }))

            first = False

        next()
        return new AST_Object({
            properties: a
        })
    )

    def as_property_name():
        tmp = S.token
        next()
        tmp_ = tmp.type
        if tmp_ == "num" or tmp_ == "string" or tmp_ == "name" or tmp_ == "operator" or tmp_ == "keyword" or tmp_ == "atom":
            return tmp
        else:
            unexpected()

    def as_name():
        tmp = S.token
        next()
        tmp_ = tmp.type
        if tmp_ == "name" or tmp_ == "operator" or tmp_ == "keyword" or tmp_ == "atom":
            return tmp.value
        else:
            unexpected()

    def as_symbol(type, noerror, token):
        token_ = token or S.token
        if not is_token(token_, "name"):
            if not noerror:
                croak("Name expected")
            return None

        name = token_.value
        sym = new (name == "this" ? AST_This : type)({
            name: (String)(token_.value),
            start: token_,
            end: token_
        })
        if not token:
            next()
        return sym

    # for generating/inserting a new symbol
    def new_symbol(type, name):
        sym = new ((name == "this" ? AST_This : type))({
            name: (String)(name),
            start: None,
            end: None
        })
        return sym

    def is_static_method(cls, method):
        if COMMON_STATIC.indexOf(method) != -1 or cls.static and cls.static.indexOf(method) != -1:
            return True
        else:
            return False

    subscripts = def(expr, allow_calls):
        start = expr.start
        if is_("punc", "."):
            next()
            return subscripts(new AST_Dot({
                start: start,
                expression: expr,
                property: as_name(),
                end: prev()
            }), allow_calls)

        if is_("punc", "[") and not S.token.nlb:
            next()
            slice_bounds = []
            is_slice = False
            if is_("punc", ":"):
                # slice [:n]
                slice_bounds.push(None)
            else:
                # slice [n?]
                slice_bounds.push(expression(False))

            if is_("punc", ":"):
                # slice [n:m?]
                is_slice = True
                next()
                if is_("punc", ":"):
                    slice_bounds.push(None)
                elif not is_("punc", "]"):
                    slice_bounds.push(expression(False))

            if is_("punc", ":"):
                # slice [n:m:o?]
                BASELIB["eslice"] = True
                next()
                if is_("punc", "]"):
                    unexpected()
                else:
                    slice_bounds.push(expression(False))

            expect("]")

            if is_slice:
                if is_("operator") and S.token.value == "=":
                    # splice-assignment (arr[start:end] = ...)
                    next()  # swallow the assignment
                    return subscripts(new AST_Splice({
                        start: start,
                        expression: expr,
                        property: slice_bounds[0] or new AST_Number({
                            value: 0
                        }),
                        property2: slice_bounds[1],
                        assignment: expression(True),
                        end: prev()
                    }), allow_calls)
                elif slice_bounds.length == 3:
                    # extended slice (arr[start:end:step])
                    slice_bounds.unshift(slice_bounds.pop())
                    if not slice_bounds[-1]:
                        slice_bounds.pop()
                        if not slice_bounds[-1]:
                            slice_bounds.pop()
                    elif not slice_bounds[-2]:
                        slice_bounds[-2] = new AST_Undefined()

                    return subscripts(new AST_Call({
                        start: start,
                        expression: new AST_SymbolRef({
                            name: "eslice"
                        }),
                        args: [expr].concat(slice_bounds),
                        end: prev()
                    }), allow_calls)
                else:
                    # regular slice (arr[start:end])
                    slice_bounds = [i == None ? new AST_Number({
                        value: 0
                    }) : i for i in slice_bounds]
                    return subscripts(new AST_Call({
                        start: start,
                        expression: new AST_Dot({
                            start: start,
                            expression: expr,
                            property: "slice",
                            end: prev()
                        }),
                        args: slice_bounds,
                        end: prev()
                    }), allow_calls)
            else:
                # regular index (arr[index])
                return subscripts(new AST_Sub({
                    start: start,
                    expression: expr,
                    property: slice_bounds[0] or new AST_Number({
                        value: 0
                    }),
                    end: prev()
                }), allow_calls)

        if allow_calls and is_("punc", "(") and not S.token.nlb:
            next()
            if isinstance(expr, AST_SymbolRef) and expr.name == "JS":
                # raw JavaScript chunk of code
                str_ = expression(False)
                if not (isinstance(str_, AST_String)):
                    token_error(prev(), "Compile-time function JS() can't process variables or expressions")

                ret = new AST_Verbatim({
                    start: start,
                    value: str_.value,
                    end: prev()
                })
                expect(")")
                return subscripts(ret, True)
            elif not expr.parens and get_class_in_scope(expr):
                # this is an object being created using a class

                # check if this class is part of our standard library
                if expr.name in STDLIB:
                    BASELIB[expr.name] = True
                    if /Error$/.test(expr.name):
                        # errors are classes
                        BASELIB["extends"] = True

                return subscripts(new AST_New({
                    start: start,
                    expression: expr,
                    args: func_call_list(),
                    end: prev()
                }), True)
            else:
                if isinstance(expr, AST_Dot):
                    c = get_class_in_scope(expr.expression)

                if c:
                    # generate class call
                    funcname = expr
                    if funcname.property == "__init__":
                        funcname.property = "constructor"

                    return subscripts(new AST_ClassCall({
                        start: start,
                        "class": expr.expression,
                        method: funcname.property,
                        "static": is_static_method(c, funcname.property),
                        args: func_call_list(),
                        end: prev()
                    }), True)
                elif isinstance(expr, AST_SymbolRef):
                    tmp_ = expr.name
                    # special functions that trigger addition of extra logic to generated JavaScript
                    if tmp_ in STDLIB:
                        BASELIB[tmp_] = True
                        # NOTE: there is intentionally no return here, we want these functions to go through regular logic
                        # after they trigger the appropriate baselib flag
                    elif tmp_ == "type":
                        return new AST_UnaryPrefix({
                            start: start,
                            operator: "typeof",
                            expression: func_call_list()[0],
                            end: prev()
                        })
                    elif tmp_ == "isinstance":
                        args = func_call_list()
                        return new AST_Binary({
                            start: start,
                            operator: "instanceof",
                            left: args[0],
                            right: args[1],
                            end: prev()
                        })

                # fall-through to basic function call
                return subscripts(new AST_Call({
                    start: start,
                    expression: expr,
                    args: func_call_list(),
                    end: prev()
                }), True)

        return expr

    maybe_unary = def(allow_calls):
        start = S.token
        if is_("operator") and UNARY_PREFIX(start.value):
            next()
            if start.value == "@":
                if is_("name") and (peek().value == "@" or peek().value == "def" or peek().value == "class"):
                    S.decorators.push(S.token.value)
                    next()
                    return new AST_EmptyStatement()
                else:
                    unexpected()

            ex = make_unary(AST_UnaryPrefix, start.value, maybe_unary(allow_calls))
            ex.start = start
            ex.end = prev()
            return ex

        val = expr_atom(allow_calls)
        while is_("operator") and UNARY_POSTFIX(S.token.value) and not S.token.nlb:
            val = make_unary(AST_UnaryPostfix, S.token.value, val)
            val.start = start
            val.end = S.token
            next()
        return val

    def make_unary(ctor, op, expr):
        return new ctor({
            operator: op,
            expression: expr
        })

    expr_op = def(left, min_prec, no_in):
        op = (is_("operator") ? S.token.value : None)
        not_in = False
        if op == "!" and peek().type == "operator" and peek().value == "in":
            next()
            op = "in"
            not_in = True

        if op == "in":
            if no_in:
                op = None
            else:
                BASELIB[op] = True

        prec = (op != None ? PRECEDENCE[op] : None)
        if prec != None and prec > min_prec:
            next()
            right = expr_op(maybe_unary(True), prec, no_in)
            ret = new AST_Binary({
                start: left.start,
                left: left,
                operator: op,
                right: right,
                end: right.end
            })
            if not_in:
                ret = new AST_UnaryPrefix({
                    start: left.start,
                    operator: "!",
                    expression: ret,
                    end: right.end
                })
            return expr_op(ret, min_prec, no_in)
        return left

    def expr_ops(no_in):
        return expr_op(maybe_unary(True), 0, no_in)

    maybe_conditional = def(no_in):
        start = S.token
        expr = expr_ops(no_in)
        if is_("operator", "?"):
            next()
            yes = expression(False)
            expect(":")
            return new AST_Conditional({
                start: start,
                condition: expr,
                consequent: yes,
                alternative: expression(False, no_in),
                end: peek()
            })
        return expr

    def is_assignable(expr):
        if not options.strict:
            return True

        tmp_ = expr[0] + ""
        if tmp_ == "dot" or tmp_ == "sub" or tmp_ == "new" or tmp_ == "call":
            return True
        elif tmp_ == "name":
            return expr[1] != "this"

    maybe_assign = def(no_in):
        start = S.token
        left = maybe_conditional(no_in)
        val = S.token.value
        if is_("operator") and ASSIGNMENT(val):
            if is_assignable(left):
                next()
                return new AST_Assign({
                    start: start,
                    left: left,
                    operator: val,
                    right: maybe_assign(no_in),
                    end: prev()
                })
            croak("Invalid assignment")
        return left

    expression = def(commas, no_in):
        # if there is an assignment, we want the sequences to pivot
        # around it to allow for tuple packing/unpacking
        start = S.token
        expr = maybe_assign(no_in)
        if commas:
            left = [ expr ]
            right = []
            while is_("punc", ",") and not peek().nlb:
                next()
                if isinstance(expr, AST_Assign):
                    # AST_Seq representation is ugly to decode for
                    # assignments, let's convert data to array now
                    # to avoid dealing with it
                    left[-1] = left[-1].left
                    if left.length == 1:
                        if isinstance(left[0], AST_Seq):
                            leftAst = seq_to_array(left[0])
                        else:
                            leftAst = left[0]
                    else:
                        leftAst = new AST_Array({
                            elements: left
                        })

                    return new AST_Assign({
                        start: start,
                        left: leftAst,
                        operator: expr.operator,
                        right: new AST_Seq({
                            car: expr.right,
                            cdr: expression(True, no_in)
                        }),
                        end: peek()
                    })

                expr = maybe_assign(no_in)
                left.push(expr)

            # transform assignments to (a, b, ...) into [a, b, ...]
            if isinstance(expr, AST_Assign) and isinstance(expr.left, AST_Seq):
                expr.left = seq_to_array(expr.left)

            # if last one was an assignment, fix it
            if left.length > 1 and isinstance(left[-1], AST_Assign):
                left[left.length - 1] = left[-1].left
                return new AST_Assign({
                    start: start,
                    left: new AST_Array({
                        elements: left
                    }),
                    operator: expr.operator,
                    right: expr.right,
                    end: peek()
                })

            #recursive sequence formation
            return (def build_seq(a):
                if a.length == 1:
                    return a[0]

                return new AST_Seq({
                    start: start,
                    car: a.shift(),
                    cdr: build_seq(a),
                    end: peek()
                })
            )(left)

        return expr

    def in_loop(cont):
        S.in_loop += 1
        ret = cont()
        S.in_loop -= 1
        return ret

    return def():
        start = S.token
        body = []
        first_token = True
        while not is_("eof"):
            element = statement()
            if first_token and isinstance(element, AST_Directive) and element.value.indexOf('#!') == 0:
                shebang = element.value
            else:
                body.push(element)
            first_token = False

        end = prev()
        toplevel = options.toplevel
        if toplevel:
            toplevel.body = toplevel.body.concat(body)
            toplevel.end = end
        else:
            toplevel = new AST_Toplevel({
                start: start,
                body: body,
                strict: def():
                    for stmt in body:
                        if isinstance(stmt, AST_Directive) and stmt.value == 'use strict':
                            return True
                    return False
                .call(this),
                shebang: shebang,
                end: end
            })

        def uniq(element, index, arr):
            return arr.lastIndexOf(element) == index

        toplevel.nonlocalvars = scan_for_nonlocal_defs(toplevel.body)
        assignments = scan_for_local_vars(toplevel.body).filter(uniq)
        callables = scan_for_top_level_callables(toplevel.body).filter(uniq)
        toplevel.localvars = []
        assignments.forEach(def(item):
            if (toplevel.nonlocalvars.indexOf(item) < 0):
                toplevel.localvars.push(new_symbol(AST_SymbolVar, item))
        )
        toplevel.exports = toplevel.localvars.concat(callables).filter(uniq)
        toplevel.submodules = []
        toplevel.classes = scan_for_classes(toplevel.body)
        toplevel.import_order = Object.keys(IMPORTED).length
        toplevel.module_id = module_id
        IMPORTED[module_id] = toplevel
        toplevel.imports = IMPORTED
        toplevel.baselib = BASELIB
        IMPORTING[module_id] = False
        return toplevel
    .call(this)

